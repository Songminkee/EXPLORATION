{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/aiffel0042/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 100000\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(os.getenv(\"HOME\")+\"/aiffel/news_summarization/data/Reviews.csv\", nrows = 100000)\n",
    "print('전체 샘플수 :',(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['Text','Summary']]\n",
    "data.head()\n",
    "\n",
    "#랜덤한 3개 샘플 출력\n",
    "data.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Text 열에서 중복을 배제한 유일한 샘플의 수 :', data['Text'].nunique())\n",
    "print('Summary 열에서 중복을 배제한 유일한 샘플의 수 :', data['Summary'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(subset = ['Text'], inplace = True)\n",
    "print('전체 샘플수 :',(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(axis = 0, inplace = True)\n",
    "print('전체 샘플수 :',(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "\n",
    "print(\"정규화 사전의 수: \",len(contractions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('불용어 개수 :', len(stopwords.words('english') ))\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 전처리 함수\n",
    "def preprocess_sentence(sentence, remove_stopwords=True):\n",
    "    sentence = sentence.lower() # 텍스트 소문자화\n",
    "    sentence = BeautifulSoup(sentence, \"lxml\").text # <br />, <a href = ...> 등의 html 태그 제거\n",
    "    sentence = re.sub(r'\\([^)]*\\)', '', sentence) # 괄호로 닫힌 문자열 (...) 제거 Ex) my husband (and myself!) for => my husband for\n",
    "    sentence = re.sub('\"','', sentence) # 쌍따옴표 \" 제거\n",
    "    sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")]) # 약어 정규화\n",
    "    sentence = re.sub(r\"'s\\b\",\"\",sentence) # 소유격 제거. Ex) roland's -> roland\n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence) # 영어 외 문자(숫자, 특수문자 등) 공백으로 변환\n",
    "    sentence = re.sub('[m]{2,}', 'mm', sentence) # m이 3개 이상이면 2개로 변경. Ex) ummmmmmm yeah -> umm yeah\n",
    "    \n",
    "    # 불용어 제거 (Text)\n",
    "    if remove_stopwords:\n",
    "        tokens = ' '.join(word for word in sentence.split() if not word in stopwords.words('english') if len(word) > 1)\n",
    "    # 불용어 미제거 (Summary)\n",
    "    else:\n",
    "        tokens = ' '.join(word for word in sentence.split() if len(word) > 1)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_text = 'Everything I bought was great, infact I ordered twice and the third ordered was<br />for my mother and father.'\n",
    "temp_summary = 'Great way to start (or finish) the day!!!'\n",
    "\n",
    "print(preprocess_sentence(temp_text))\n",
    "print(preprocess_sentence(temp_summary, False))  # 불용어를 제거하지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text = []\n",
    "\n",
    "# 전체 Text 데이터에 대한 전처리 : 10분 이상 시간이 걸릴 수 있습니다. \n",
    "for s in data['Text']:\n",
    "    clean_text.append(preprocess_sentence(s))\n",
    "\n",
    "# 전처리 후 출력\n",
    "clean_text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_summary = []\n",
    "\n",
    "# 전체 Summary 데이터에 대한 전처리 : 5분 이상 시간이 걸릴 수 있습니다. \n",
    "for s in data['Summary']:\n",
    "    clean_summary.append(preprocess_sentence(s, False))\n",
    "\n",
    "clean_summary[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Text'] = clean_text\n",
    "data['Summary'] = clean_summary\n",
    "\n",
    "# 빈 값을 Null 값으로 변환\n",
    "data.replace('', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(axis=0, inplace=True)\n",
    "print('전체 샘플수 :',(len(data)))#데이터 전처리 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 길이 분포 출력\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_len = [len(s.split()) for s in data['Text']]\n",
    "summary_len = [len(s.split()) for s in data['Summary']]\n",
    "\n",
    "print('텍스트의 최소 길이 : {}'.format(np.min(text_len)))\n",
    "print('텍스트의 최대 길이 : {}'.format(np.max(text_len)))\n",
    "print('텍스트의 평균 길이 : {}'.format(np.mean(text_len)))\n",
    "print('요약의 최소 길이 : {}'.format(np.min(summary_len)))\n",
    "print('요약의 최대 길이 : {}'.format(np.max(summary_len)))\n",
    "print('요약의 평균 길이 : {}'.format(np.mean(summary_len)))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.boxplot(summary_len)\n",
    "plt.title('Summary')\n",
    "plt.subplot(1,2,2)\n",
    "plt.boxplot(text_len)\n",
    "plt.title('Text')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.title('Summary')\n",
    "plt.hist(summary_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "plt.title('Text')\n",
    "plt.hist(text_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_max_len = 50\n",
    "summary_max_len = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def below_threshold_len(max_len, nested_list):\n",
    "  cnt = 0\n",
    "  for s in nested_list:\n",
    "    if(len(s.split()) <= max_len):\n",
    "        cnt = cnt + 1\n",
    "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "below_threshold_len(text_max_len, data['Text'])\n",
    "below_threshold_len(summary_max_len,  data['Summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['Text'].apply(lambda x: len(x.split()) <= text_max_len)]\n",
    "data = data[data['Summary'].apply(lambda x: len(x.split()) <= summary_max_len)]\n",
    "print('전체 샘플수 :',(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#요약 데이터에는 시작 토큰과 종료 토큰을 추가한다.\n",
    "data['decoder_input'] = data['Summary'].apply(lambda x : 'sostoken '+ x)\n",
    "data['decoder_target'] = data['Summary'].apply(lambda x : x + ' eostoken')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = np.array(data['Text']) # 인코더의 입력\n",
    "decoder_input = np.array(data['decoder_input']) # 디코더의 입력\n",
    "decoder_target = np.array(data['decoder_target']) # 디코더의 레이블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_of_val = int(len(encoder_input)*0.2)\n",
    "print('테스트 데이터의 수 :',n_of_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :',len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :',len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :',len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 7\n",
    "total_cnt = len(src_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in src_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab = 8000\n",
    "src_tokenizer = Tokenizer(num_words = src_vocab) # 단어 집합의 크기를 8,000으로 제한\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 단어 집합 재생성."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train) \n",
    "encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)\n",
    "\n",
    "#잘 진행되었는지 샘플 출력\n",
    "print(encoder_input_train[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_tokenizer = Tokenizer()\n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 6\n",
    "total_cnt = len(tar_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tar_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_vocab = 2000\n",
    "tar_tokenizer = Tokenizer(num_words = tar_vocab) \n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "tar_tokenizer.fit_on_texts(decoder_target_train)\n",
    "\n",
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train) \n",
    "decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n",
    "decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n",
    "decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)\n",
    "\n",
    "#잘 변환되었는지 확인\n",
    "print('input')\n",
    "print('input ',decoder_input_train[:5])\n",
    "print('target')\n",
    "print('decoder ',decoder_target_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_train = [index for index, sentence in enumerate(decoder_input_train) if len(sentence) == 1]\n",
    "drop_test = [index for index, sentence in enumerate(decoder_input_test) if len(sentence) == 1]\n",
    "\n",
    "print('삭제할 훈련 데이터의 개수 :',len(drop_train))\n",
    "print('삭제할 테스트 데이터의 개수 :',len(drop_test))\n",
    "\n",
    "encoder_input_train = np.delete(encoder_input_train, drop_train, axis=0)\n",
    "decoder_input_train = np.delete(decoder_input_train, drop_train, axis=0)\n",
    "decoder_target_train = np.delete(decoder_target_train, drop_train, axis=0)\n",
    "\n",
    "encoder_input_test = np.delete(encoder_input_test, drop_test, axis=0)\n",
    "decoder_input_test = np.delete(decoder_input_test, drop_test, axis=0)\n",
    "decoder_target_test = np.delete(decoder_target_test, drop_test, axis=0)\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :',len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :',len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :',len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_train = pad_sequences(encoder_input_train, maxlen = text_max_len, padding='post')\n",
    "encoder_input_test = pad_sequences(encoder_input_test, maxlen = text_max_len, padding='post')\n",
    "decoder_input_train = pad_sequences(decoder_input_train, maxlen = summary_max_len, padding='post')\n",
    "decoder_target_train = pad_sequences(decoder_target_train, maxlen = summary_max_len, padding='post')\n",
    "decoder_input_test = pad_sequences(decoder_input_test, maxlen = summary_max_len, padding='post')\n",
    "decoder_target_test = pad_sequences(decoder_target_test, maxlen = summary_max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "# 인코더 설계 시작\n",
    "embedding_dim = 128\n",
    "hidden_size = 256\n",
    "\n",
    "# 인코더\n",
    "encoder_inputs = Input(shape=(text_max_len,))\n",
    "\n",
    "# 인코더의 임베딩 층\n",
    "enc_emb = Embedding(src_vocab, embedding_dim)(encoder_inputs)\n",
    "\n",
    "# 인코더의 LSTM 1\n",
    "encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4, recurrent_dropout = 0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "# 인코더의 LSTM 2\n",
    "encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "# 인코더의 LSTM 3\n",
    "encoder_lstm3 = LSTM(hidden_size, return_state=True, return_sequences=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 설계\n",
    "\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "# 디코더의 임베딩 층\n",
    "dec_emb_layer = Embedding(tar_vocab, embedding_dim)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 디코더의 LSTM\n",
    "decoder_lstm = LSTM(hidden_size, return_sequences = True, return_state = True, dropout = 0.4, recurrent_dropout=0.2)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state = [state_h, state_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation = 'softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_outputs) \n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/thushv89/attention_keras/master/src/layers/attention.py\", filename=\"attention.py\")\n",
    "from attention import AttentionLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어텐션 층(어텐션 함수)\n",
    "attn_layer = AttentionLayer(name='attention_layer')\n",
    "# 인코더와 디코더의 모든 time step의 hidden state를 어텐션 층에 전달하고 결과를 리턴\n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
    "\n",
    "# 어텐션의 결과와 디코더의 hidden state들을 연결\n",
    "decoder_concat_input = Concatenate(axis = -1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_concat_input)\n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 2)\n",
    "history = model.fit(x = [encoder_input_train, decoder_input_train], y = decoder_target_train, \\\n",
    "          validation_data = ([encoder_input_test, decoder_input_test], decoder_target_test),\n",
    "          batch_size = 256, callbacks=[es], epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2text(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            temp = temp + src_index_to_word[i]+' '\n",
    "    return temp\n",
    "\n",
    "# 요약문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2summary(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=tar_word_to_index['sostoken']) and i!=tar_word_to_index['eostoken']):\n",
    "            temp = temp + tar_index_to_word[i] + ' '\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50, 100):\n",
    "    print(\"원문 :\", seq2text(encoder_input_test[i]))\n",
    "    print(\"실제 요약 :\", seq2summary(decoder_input_test[i]))\n",
    "    print(\"예측 요약 :\", decode_sequence(encoder_input_test[i].reshape(1, text_max_len)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 뉴스기사 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/aiffel0042/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import urllib.request\n",
    "\n",
    "\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/sunnysai12345/News_Summary/master/news_summary_more.csv\", filename=\"news_summary_more.csv\")\n",
    "data = pd.read_csv('news_summary_more.csv', encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10705</th>\n",
       "      <td>Cash enables people to evade tax: Arun Jaitley...</td>\n",
       "      <td>On the second anniversary of demonetisation, F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11057</th>\n",
       "      <td>Virat Kohli came to bat the same day his fathe...</td>\n",
       "      <td>Team India captain Virat Kohli came out to bat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48702</th>\n",
       "      <td>Tesla posts biggest quarterly loss despite 55%...</td>\n",
       "      <td>American automaker Tesla has reported a loss o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20389</th>\n",
       "      <td>How are celebrities contributing to Kerala flo...</td>\n",
       "      <td>Sushant Singh Rajput donated Ã¢ÂÂ¹1 crore on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94254</th>\n",
       "      <td>Bihar police stations to plant trees to promot...</td>\n",
       "      <td>All the police stations in Bihar will be plant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4080</th>\n",
       "      <td>Virat Kohli ends year as the top-ranked Test p...</td>\n",
       "      <td>Indian captain Virat Kohli is ending the year ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36073</th>\n",
       "      <td>Facebook gained $21 billion during Zuckerberg'...</td>\n",
       "      <td>Facebook added nearly $21 billion in market va...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53226</th>\n",
       "      <td>Civilian deaths from air strikes rose by 80% i...</td>\n",
       "      <td>The deaths of civilians resulting from air-lau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35376</th>\n",
       "      <td>This is how internet works: Facebook on tracki...</td>\n",
       "      <td>Responding to the concerns about the collectio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11803</th>\n",
       "      <td>Flipkart posts a total loss of Ã¢ÂÂ¹3,224 cro...</td>\n",
       "      <td>Flipkart's e-commerce unit Flipkart Internet a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               headlines  \\\n",
       "10705  Cash enables people to evade tax: Arun Jaitley...   \n",
       "11057  Virat Kohli came to bat the same day his fathe...   \n",
       "48702  Tesla posts biggest quarterly loss despite 55%...   \n",
       "20389  How are celebrities contributing to Kerala flo...   \n",
       "94254  Bihar police stations to plant trees to promot...   \n",
       "4080   Virat Kohli ends year as the top-ranked Test p...   \n",
       "36073  Facebook gained $21 billion during Zuckerberg'...   \n",
       "53226  Civilian deaths from air strikes rose by 80% i...   \n",
       "35376  This is how internet works: Facebook on tracki...   \n",
       "11803  Flipkart posts a total loss of Ã¢ÂÂ¹3,224 cro...   \n",
       "\n",
       "                                                    text  \n",
       "10705  On the second anniversary of demonetisation, F...  \n",
       "11057  Team India captain Virat Kohli came out to bat...  \n",
       "48702  American automaker Tesla has reported a loss o...  \n",
       "20389  Sushant Singh Rajput donated Ã¢ÂÂ¹1 crore on ...  \n",
       "94254  All the police stations in Bihar will be plant...  \n",
       "4080   Indian captain Virat Kohli is ending the year ...  \n",
       "36073  Facebook added nearly $21 billion in market va...  \n",
       "53226  The deaths of civilians resulting from air-lau...  \n",
       "35376  Responding to the concerns about the collectio...  \n",
       "11803  Flipkart's e-commerce unit Flipkart Internet a...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 98360\n"
     ]
    }
   ],
   "source": [
    "data.drop_duplicates(subset = ['text'], inplace = True)\n",
    "print('전체 샘플수 :',(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "headlines    0\n",
      "text         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정규화 사전의 수:  120\n"
     ]
    }
   ],
   "source": [
    "contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "\n",
    "print(\"정규화 사전의 수: \",len(contractions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 개수 : 179\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print('불용어 개수 :', len(stopwords.words('english') ))\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 전처리 함수\n",
    "def preprocess_sentence(sentence, remove_stopwords=True):\n",
    "    sentence = sentence.lower() # 텍스트 소문자화\n",
    "    sentence = BeautifulSoup(sentence, \"lxml\").text # <br />, <a href = ...> 등의 html 태그 제거\n",
    "    sentence = re.sub(r'\\([^)]*\\)', '', sentence) # 괄호로 닫힌 문자열 (...) 제거 Ex) my husband (and myself!) for => my husband for\n",
    "    sentence = re.sub('\"','', sentence) # 쌍따옴표 \" 제거\n",
    "    sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")]) # 약어 정규화\n",
    "    sentence = re.sub(r\"'s\\b\",\"\",sentence) # 소유격 제거. Ex) roland's -> roland\n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence) # 영어 외 문자(숫자, 특수문자 등) 공백으로 변환\n",
    "    sentence = re.sub('[m]{2,}', 'mm', sentence) # m이 3개 이상이면 2개로 변경. Ex) ummmmmmm yeah -> umm yeah\n",
    "    \n",
    "    # 불용어 제거 (Text)\n",
    "    if remove_stopwords:\n",
    "        tokens = ' '.join(word for word in sentence.split() if not word in stopwords.words('english') if len(word) > 1)\n",
    "    # 불용어 미제거 (Summary)\n",
    "    else:\n",
    "        tokens = ' '.join(word for word in sentence.split() if len(word) > 1)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['saurav kant alumnus upgrad iiit pg program machine learning artificial intelligence sr systems engineer infosys almost years work experience program upgrad degree career support helped transition data scientist tech mahindra salary hike upgrad online power learning powered lakh careers',\n",
       " 'kunal shah credit card bill payment platform cred gave users chance win free food swiggy one year pranav kaushik delhi techie bagged reward spending cred coins users get one cred coin per rupee bill paid used avail rewards brands like ixigo bookmyshow ubereats cult fit',\n",
       " 'new zealand defeated india wickets fourth odi hamilton thursday win first match five match odi series india lost international match rohit sharma captaincy consecutive victories dating back march match witnessed india getting seventh lowest total odi cricket history',\n",
       " 'aegon life iterm insurance plan customers enjoy tax benefits premiums paid save taxes plan provides life cover age years also customers options insure critical illnesses disability accidental death benefit rider life cover age years',\n",
       " 'speaking sexual harassment allegations rajkumar hirani sonam kapoor said known hirani many years true metoo movement get derailed metoo movement always believe woman case need reserve judgment added hirani accused assistant worked sanju']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text = []\n",
    "\n",
    "# 전체 Text 데이터에 대한 전처리 : 10분 이상 시간이 걸릴 수 있습니다. \n",
    "for s in data['text']:\n",
    "    clean_text.append(preprocess_sentence(s))\n",
    "\n",
    "# 전처리 후 출력\n",
    "clean_text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['upgrad learner switches to career in ml al with salary hike',\n",
       " 'delhi techie wins free food from swiggy for one year on cred',\n",
       " 'new zealand end rohit sharma led india match winning streak',\n",
       " 'aegon life iterm insurance plan helps customers save tax',\n",
       " 'have known hirani for yrs what if metoo claims are not true sonam']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_summary = []\n",
    "\n",
    "# 전체 Summary 데이터에 대한 전처리 : 5분 이상 시간이 걸릴 수 있습니다. \n",
    "for s in data['headlines']:\n",
    "    clean_summary.append(preprocess_sentence(s, False))\n",
    "\n",
    "clean_summary[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Text'] = clean_text\n",
    "data['Summary'] = clean_summary\n",
    "\n",
    "# 빈 값을 Null 값으로 변환\n",
    "data.replace('', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "headlines    0\n",
       "text         0\n",
       "Text         0\n",
       "Summary      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 98360\n"
     ]
    }
   ],
   "source": [
    "data.dropna(axis=0, inplace=True)\n",
    "print('전체 샘플수 :',(len(data)))#데이터 전처리 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트의 최소 길이 : 1\n",
      "텍스트의 최대 길이 : 60\n",
      "텍스트의 평균 길이 : 35.09968483123221\n",
      "요약의 최소 길이 : 1\n",
      "요약의 최대 길이 : 16\n",
      "요약의 평균 길이 : 9.299532330215534\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dfbxdVX3n8c8X0EgV5CkyMQEvSLQC1QAxpSNalCpRnIIdwDCjoNJGKRastk5iO0p9NVMYW7HYGo2FEpCnDIhkBEUEKXUMwQtEEp7GAKlckiEREKJIasJ3/tjryMnNuTcn2feck5N836/Xfp19fvvhrEUgP9Zea68l20RERGytnXpdgIiI6G9JJBERUUsSSURE1JJEEhERtSSRRERELUkkERFRSxJJRETUkkQS0SGSft60PS/pl03f/+tW3O9oSUOdKGtEHbv0ugAR2yvbL2vsS1oB/KHt7/auRBGdkRZJRJdJ2knSLEkPSXpC0gJJe5VjcyVd3XTueZJulvRS4FvAK5taNa/sVR0imiWRRHTfWcAJwO8CrwSeAv6xHPsE8HpJH5D0ZuB04DTbvwDeCay0/bKyrexB2SM2kUdbEd33YeCjtocAJJ0D/ETS+20/K+l9wLeBtcCfNM6L2FYlkUR036uAayU93xTbAOwLPGb7DkkPA68AFvSigBFbIo+2IrrvUeCdtvdo2l5i+zEASWcC44CVwCebrstU3bFNSiKJ6L4vA3MkvQpA0nhJx5f91wB/DbwPeD/wSUlTynWPA3tLenkPyhwxoiSSiO77e2Ah8B1Ja4Hbgd+WtAvwNeA82z+y/WPgU8ClksbZfgC4AnhY0s8yaiu2FcrCVhERUUdaJBERUUsSSURE1JJEEhERtSSRRERELTvcC4n77LOPBwYGel2MiIi+cuedd/7U9vhWx3a4RDIwMMDg4GCvixER0Vck/dtIx/JoKyIiakkiiYiIWpJIIiKiliSSiIioJYkkIiJqSSKJiIhakkgiIqKWJJKIiKgliSQiImrp2JvtkvYDLgH+A/A8MM/230vaC7gKGABWACfbfqpcMxs4nWr96rNs31jiRwAXA7sCNwBn27akceU3jgCeAN5re0Wn6hTRrwZmXT/q8RXnHtelksT2qJMtkvXAJ2y/DjgSOFPSwcAs4Gbbk4Gby3fKsRnAIcB04EuSdi73mgvMBCaXbXqJnw48Zfsg4HzgvA7WJyIiWuhYIrG9yvZdZX8tcD8wETgemF9Omw+cUPaPB660vc72I8ByYJqkCcDuthe5Ws7xkmHXNO51NXCMJHWqThERsamu9JFIGgAOAxYD+9peBVWyAV5RTpsIPNp02VCJTSz7w+MbXWN7PfA0sHeL358paVDS4Jo1a8amUhERAXQhkUh6GXAN8DHbz4x2aouYR4mPds3GAXue7am2p44f33IW5IiI2EodTSSSXkSVRC6z/fUSfrw8rqJ8ri7xIWC/pssnAStLfFKL+EbXSNoFeDnw5NjXJCIiRtKxRFL6Ki4E7rf9+aZDC4HTyv5pwHVN8RmSxkk6gKpT/Y7y+GutpCPLPU8ddk3jXicCt5R+lIiI6JJOLmz1JuD9wFJJS0rsU8C5wAJJpwM/AU4CsH2vpAXAfVQjvs60vaFcdwYvDP/9VtmgSlSXSlpO1RKZ0cH6RERECx1LJLa/T+s+DIBjRrhmDjCnRXwQOLRF/DlKIoqIiN7Im+0REVFLEklERNSSRBIREbUkkURERC1JJBERUUsSSURE1JJEEhERtSSRRERELUkkERFRSxJJRETUkkQSERG1JJFEREQtSSQREVFLEklERNSSRBIREbUkkURERC2dXGr3IkmrJS1ril0laUnZVjRWTpQ0IOmXTce+3HTNEZKWSlou6YKy3C5lSd6rSnyxpIFO1SUiIkbWyRbJxcD05oDt99qeYnsKcA3w9abDDzWO2f5IU3wuMJNqDffJTfc8HXjK9kHA+cB5nalGRESMpmOJxPZtVOuob6K0Kk4GrhjtHpImALvbXmTbwCXACeXw8cD8sn81cEyjtRIREd3Tqz6SNwOP2/5xU+wASXdL+hdJby6xicBQ0zlDJdY49iiA7fXA08DenS12REQMt0uPfvcUNm6NrAL2t/2EpCOAb0g6BGjVwnD5HO3YRiTNpHo8xv7777/VhY6IiE11vUUiaRfgD4CrGjHb62w/UfbvBB4CXkPVApnUdPkkYGXZHwL2a7rnyxnhUZrteban2p46fvz4sa1QRMQOrhePtn4PeMD2rx9ZSRovaeeyfyBVp/rDtlcBayUdWfo/TgWuK5ctBE4r+ycCt5R+lIiI6KJODv+9AlgEvFbSkKTTy6EZbNrJ/hbgHkk/ouo4/4jtRuviDOCfgOVULZVvlfiFwN6SlgMfB2Z1qi4RETGyjvWR2D5lhPgHWsSuoRoO3Or8QeDQFvHngJPqlTIiIurKm+0REVFLEklERNSSRBIREbUkkURERC1JJBERUUsSSURE1JJEEhERtfRqrq2I2EIDs64f9fiKc4/rUkkiNpYWSURE1JJEEhERtSSRRERELUkkERFRSxJJRETUkkQSERG1JJFEREQtSSQREVFLEklERNTSyaV2L5K0WtKyptg5kh6TtKRs72o6NlvSckkPSjq2KX6EpKXl2AVl7XYkjZN0VYkvljTQqbpERMTINptIJJ0kabey/5eSvi7p8DbufTEwvUX8fNtTynZDue/BVGu5H1Ku+ZKkncv5c4GZwOSyNe55OvCU7YOA84Hz2ihTRESMsXZaJP/d9lpJRwHHAvOp/nIfle3bgCfbLMfxwJW219l+BFgOTJM0Adjd9iLbBi4BTmi6Zn7Zvxo4ptFaiYiI7mknkWwon8cBc21fB7y4xm9+VNI95dHXniU2EXi06ZyhEptY9ofHN7rG9nrgaWDvVj8oaaakQUmDa9asqVH0iIgYrp1E8pikrwAnAzdIGtfmda3MBV4NTAFWAX9X4q1aEh4lPto1mwbteban2p46fvz4LStxRESMqp2EcDJwIzDd9s+AvYA/35ofs/247Q22nwe+Ckwrh4aA/ZpOnQSsLPFJLeIbXSNpF+DltP8oLSIixshmE4ntZ4HVwFEltB748db8WOnzaHgP0BjRtRCYUUZiHUDVqX6H7VXAWklHlv6PU4Hrmq45reyfCNxS+lEiIqKLNruwlaTPAFOB1wL/DLwI+Brwps1cdwVwNLCPpCHgM8DRkqZQPYJaAXwYwPa9khYA91ElqjNtN/pmzqAaAbYr8K2yAVwIXCppOVVLZEY7FY6IiLHVzgqJ7wEOA+4CsL2yMRx4NLZPaRG+cJTz5wBzWsQHgUNbxJ8DTtpcOSIiorPa6SP59/LIyACSXtrZIkVERD9pJ5EsKKO29pD0R8B3qTrKIyIiNv9oy/bfSno78AxVP8mnbd/U8ZJFRERfaKePhJI4kjwiImITIyYSSWtp/YKfANvevWOlioiIvjFiIrG92ZFZERERbT3aKrP9HkXVQvm+7bs7WqqI2KYMzLp+xGMrzj2uiyWJbVE708h/mmqW3b2BfYCLJf1lpwsWERH9oZ0WySnAYeUFQCSdS/Vy4l93smAREdEf2nmPZAXwkqbv44CHOlKaiIjoO+20SNYB90q6iaqP5O3A9yVdAGD7rA6WLyIitnHtJJJry9Zwa2eKEhER/aidN9vnb+6ciIjYcbUzauvdku6W9KSkZyStlfRMNwoXERHbvnYebX0B+ANgaRaOioiI4doZtfUosCxJJCIiWmknkXwSuEHSbEkfb2ybu0jSRZJWS1rWFPucpAck3SPpWkl7lPiApF9KWlK2Lzddc4SkpZKWS7qgLLlLWZb3qhJfLGlgSysfERH1tZNI5gDPUr1LslvTtjkXA9OHxW4CDrX9euD/ArObjj1ke0rZPtIUnwvMpFrHfXLTPU8HnrJ9EHA+cF4bZYqIiDHWTh/JXrbfsaU3tn3b8FaC7e80fb0dOHG0e0iaAOxue1H5fglwAtW67ccD55RTrwb+QZLyCC4iorvaaZF8V9IWJ5I2fIgqITQcUEaH/YukN5fYRGCo6ZyhEmscexTA9nrgaar5wDYhaaakQUmDa9asGcs6RETs8NpJJGcC3y59GGMy/FfSXwDrgctKaBWwv+3DgI8Dl0vanWrtk+EaLY7Rjm0ctOfZnmp76vjx4+sUPSIihmnnhcQxXZdE0mnAu4FjGo+hbK+jmooF23dKegh4DVULZFLT5ZOAlWV/CNgPGJK0C/By4MmxLGtERGxeu+uR7EnV0f3ryRtt37alPyZpOvDfgN+1/WxTfDzwpO0Nkg4sv/Ww7SdLC+hIYDFwKvDFctlC4DRgEVVfyy3pH4mI6L7NJhJJfwicTdUaWAIcSfWX99s2c90VwNHAPpKGgM9QjdIaB9xURvHeXkZovQX4rKT1wAbgI7YbrYszqEaA7UrVp9LoV7kQuFTScqqWyIy2ahwREWOqnRbJ2cAbqf7Sf6uk3wT+anMX2T6lRfjCEc69BrhmhGODwKEt4s8BJ22uHBER0VntdLY/17So1TjbDwCv7WyxIiKiX7TTIhkqb6B/g+qR1FO80OEdERE7uHZGbb2n7J4j6XtUo6O+3dFSRURE32hnGvlXSxrX+AoMAL/RyUJFRET/aKeP5Bpgg6SDqDrLDwAu72ipIiKib7STSJ4vU5C8B/iC7T8FJnS2WBER0S/aSSS/knQK1ct/3yyxF3WuSBER0U/aSSQfBH4HmGP7EUkHAF/rbLEiIqJftDNq6z7grKbvjwDndrJQERHRP9ppkURERIwoiSQiImoZMZFIurR8nt294kRERL8ZrUVyhKRXAR+StKekvZq3bhUwIiK2baN1tn+ZaiqUA4E72XhFQpd4RETs4EZskdi+wPbrgItsH2j7gKYtSSQiIoD2hv+eIekNwJtL6Dbb93S2WBER0S/ambTxLOAy4BVlu0zSn3S6YBER0R/aGf77h8Bv2/607U9TLbX7R5u7SNJFklZLWtYU20vSTZJ+XD73bDo2W9JySQ9KOrYpfoSkpeXYBSpr9EoaJ+mqEl8saaD9akdExFhpJ5GIah31hg1s3PE+kouB6cNis4CbbU8Gbi7fkXQw1Zrrh5RrviRp53LNXGAmMLlsjXueDjxl+yDgfOC8NsoUERFjrJ1E8s/AYknnSDoHuJ0R1l5vZvs24Mlh4eOB+WV/PnBCU/xK2+vKFCzLgWmSJgC7215k28Alw65p3Otq4JhGayUiIrqnnc72z0u6FTiKqiXyQdt3b+Xv7Wt7VbnvKkmvKPGJVAmqYajEflX2h8cb1zxa7rVe0tPA3sBPh/+opJlUrRr233//rSx6xLZtYNb1vS5C7KDaWbMd23cBd3WwHK1aEh4lPto1mwbtecA8gKlTp7Y8JyIitk6359p6vDyuonyuLvEhYL+m8yYBK0t8Uov4RtdI2oVqLfnhj9IiIqLDup1IFlItkEX5vK4pPqOMxDqAqlP9jvIYbK2kI0v/x6nDrmnc60TgltKPEhERXTTqo60ycupG27+3pTeWdAVwNLCPpCHgM1TrmCyQdDrwE+AkANv3SloA3AesB8603RgpdgbVCLBdgW+VDaoO/0slLadqiczY0jJGRER9oyYS2xskPSvp5baf3pIb2z5lhEPHjHD+HGBOi/ggcGiL+HOURBQREb3TTmf7c8BSSTcBv2gEbZ818iUREbGjaCeRXF+2iNhOZehw1NHOeyTzJe0K7G/7wS6UKSIi+kg7kzb+J2AJ1dokSJoiaWGnCxYREf2hneG/5wDTgJ8B2F4CHNDBMkVERB9pJ5GsbzFiK+9rREQE0F5n+zJJ/wXYWdJk4CzgB50tVkRE9It2WiR/QjW9+zrgCuAZ4GOdLFRERPSPdkZtPQv8haTzqq9e2/liRUREv2hn1NYbJS0F7qF6MfFHko7ofNEiIqIftNNHciHwx7b/FUDSUVSLXb2+kwWLiIj+0E4fydpGEgGw/X0gj7ciIgIYpUUi6fCye4ekr1B1tBt4L3Br54sWERH9YLRHW3837PtnmvbzHklERACjJBLbb+1mQSIioj9ttrNd0h5UKxMONJ+faeQjIgLa62y/gSqJLAXubNq2iqTXSlrStD0j6WOSzpH0WFP8XU3XzJa0XNKDko5tih8haWk5dkFZjjciIrqoneG/L7H98bH6wTIV/RT49VK+jwHXAh8Ezrf9t83nSzqYahndQ4BXAt+V9JqyFO9cYCZwO1XCm84LS/FGREQXtNMiuVTSH0maIGmvxjZGv38M8JDtfxvlnOOBK22vs/0IsByYJmkCsLvtRbYNXAKcMEblioiINrWTSP4d+BywiBceaw2O0e/PoBpW3PBRSfdIukjSniU2EXi06ZyhEptY9ofHNyFppqRBSYNr1qwZo6JHRAS0l0g+Dhxke8D2AWU7sO4PS3ox8PvA/yqhucCrqR57reKF4cet+j08SnzToD3P9lTbU8ePH1+r3BERsbF2Esm9wLMd+O13AnfZfhzA9uO2N9h+Hvgq1WJaULU09mu6bhKwssQntYhHREQXtdPZvgFYIul7VFPJA2My/PcUmh5rSZpge1X5+h5gWdlfCFwu6fNUne2TgTtsb5C0VtKRwGKqIcpfrFmmiIjYQu0kkm+UbcxI+g3g7cCHm8L/U9IUqsdTKxrHbN8raQFwH7AeOLOM2AI4A7gY2JVqtFZGbEVEdFk765HMH+sfLWuc7D0s9v5Rzp8DzGkRHwQOHevyRURE+9p5s/0RWnRij0WHe0RE9L92Hm1Nbdp/CXASMFbvkURERJ/b7Kgt2080bY/Z/gLwti6ULSIi+kA7j7YOb/q6E1ULZbeOlSgiIvpKO4+2mtclWU81ourkjpQmIiL6TjujtrIuSUREjKidR1vjgP/MpuuRfLZzxYqIiH7RzqOt64CnqSZrXLeZcyMiYgfTTiKZZHt6x0sSERF9qZ1JG38g6bc6XpKIiOhL7bRIjgI+UN5wX0c1fbttv76jJYuIiL7QTiJ5Z8dLERERfaud4b+jLYMbEWNkYNb1vS5CxFZpp48kIiJiREkkERFRSxJJRETUkkQSERG19CSRSFohaamkJZIGS2wvSTdJ+nH53LPp/NmSlkt6UNKxTfEjyn2WS7pAknpRn4iIHVkvWyRvtT3FdmPhrFnAzbYnAzeX70g6GJgBHAJMB74kaedyzVxgJjC5bHkDPyKiy7alR1vHA4314ecDJzTFr7S9zvYjwHJgmqQJwO62F9k2cEnTNRER0SXtvJDYCQa+I8nAV2zPA/a1vQrA9ipJryjnTgRub7p2qMR+VfaHxzchaSZVy4X9999/LOsREZsx2vsxK849rosliU7pVSJ5k+2VJVncJOmBUc5t1e/hUeKbBqtENQ9g6tSpLc+JiIit05NHW7ZXls/VwLXANODx8riK8rm6nD4E7Nd0+SRgZYlPahGPiIgu6nqLRNJLgZ1sry377wA+CywETgPOLZ/XlUsWApdL+jzwSqpO9Ttsb5C0VtKRwGLgVOCL3a1NxMY2N81JHuXE9qgXj7b2Ba4tI3V3AS63/W1JPwQWSDod+AlwEoDteyUtAO6jWjP+TNsbyr3OAC4GdgW+VbaIiOiiricS2w8Db2gRfwI4ZoRr5gBzWsQHgUPHuowR0b5MNhnb0vDfiIjoQ0kkERFRSxJJRETU0qv3SCJ2SOlPiO1RWiQREVFLEklERNSSRBIREbUkkURERC1JJBERUUsSSURE1JJEEhERtSSRRERELUkkERFRSxJJRETUkkQSERG1JJFEREQtXU8kkvaT9D1J90u6V9LZJX6OpMckLSnbu5qumS1puaQHJR3bFD9C0tJy7AKVZRcjIqJ7ejH773rgE7bvkrQbcKekm8qx823/bfPJkg4GZgCHUK3Z/l1JrynL7c4FZgK3AzcA08lyuxERXdX1FontVbbvKvtrgfuBiaNccjxwpe11th8BlgPTJE0Adre9yLaBS4ATOlz8iIgYpqd9JJIGgMOAxSX0UUn3SLpI0p4lNhF4tOmyoRKbWPaHx1v9zkxJg5IG16xZM4Y1iIiIniUSSS8DrgE+ZvsZqsdUrwamAKuAv2uc2uJyjxLfNGjPsz3V9tTx48fXLntERLygJ4lE0ouokshltr8OYPtx2xtsPw98FZhWTh8C9mu6fBKwssQntYhHREQX9WLUloALgfttf74pPqHptPcAy8r+QmCGpHGSDgAmA3fYXgWslXRkueepwHVdqURERPxaL0ZtvQl4P7BU0pIS+xRwiqQpVI+nVgAfBrB9r6QFwH1UI77OLCO2AM4ALgZ2pRqtlRFbERFd1vVEYvv7tO7fuGGUa+YAc1rEB4FDx650ERGxpfJme0RE1JJEEhERtSSRRERELUkkERFRSxJJRETUkkQSERG1JJFEREQtSSQREVFLL95sj4gAYGDW9aMeX3HucV0qSdSRRBKxhTb3l1/EjiaJJGKYJIptR1os/SF9JBERUUsSSURE1JJEEhERtSSRRERELUkkERFRSxJJRETU0veJRNJ0SQ9KWi5pVq/LExGxo+nr90gk7Qz8I/B2YAj4oaSFtu/rbcliW5b3RLYfo/1Z5h2T7unrRAJMA5bbfhhA0pXA8UASyQ4uySLyMmP39HsimQg82vR9CPjt4SdJmgnMLF9/LunBNu69D/DT2iXcdmxP9dme6gLbV336pi46r63T+qY+bapTn1eNdKDfE4laxLxJwJ4HzNuiG0uDtqdubcG2NdtTfbanusD2VZ/tqS6Q+rSr3zvbh4D9mr5PAlb2qCwRETukfk8kPwQmSzpA0ouBGcDCHpcpImKH0tePtmyvl/RR4EZgZ+Ai2/eO0e236FFYH9ie6rM91QW2r/psT3WB1KctsjfpUoiIiGhbvz/aioiIHksiiYiIWpJIWujnaVckXSRptaRlTbG9JN0k6cflc89elnFLSNpP0vck3S/pXklnl3jf1UnSSyTdIelHpS5/VeJ9V5dmknaWdLekb5bvfVsfSSskLZW0RNJgifVlfSTtIelqSQ+U/35+p1N1SSIZpmnalXcCBwOnSDq4t6XaIhcD04fFZgE3254M3Fy+94v1wCdsvw44Ejiz/Hn0Y53WAW+z/QZgCjBd0pH0Z12anQ3c3/S93+vzVttTmt636Nf6/D3wbdu/CbyB6s+oM3Wxna1pA34HuLHp+2xgdq/LtYV1GACWNX1/EJhQ9icAD/a6jDXqdh3V3Gp9XSfgN4C7qGZi6Nu6UL27dTPwNuCbJdbP9VkB7DMs1nf1AXYHHqEMqOp0XdIi2VSraVcm9qgsY2Vf26sAyucrelyerSJpADgMWEyf1qk8BloCrAZust23dSm+AHwSeL4p1s/1MfAdSXeWqZWgP+tzILAG+Ofy2PGfJL2UDtUliWRTbU27Et0l6WXANcDHbD/T6/JsLdsbbE+h+j/5aZIO7XWZtpakdwOrbd/Z67KMoTfZPpzq0faZkt7S6wJtpV2Aw4G5tg8DfkEHH8klkWxqe5x25XFJEwDK5+oel2eLSHoRVRK5zPbXS7iv62T7Z8CtVP1Z/VqXNwG/L2kFcCXwNklfo3/rg+2V5XM1cC3VDOP9WJ8hYKi0eAGupkosHalLEsmmtsdpVxYCp5X906j6GfqCJAEXAvfb/nzTob6rk6TxkvYo+7sCvwc8QB/WBcD2bNuTbA9Q/Xdyi+330af1kfRSSbs19oF3AMvow/rY/n/Ao5JeW0LHUC2v0ZG65M32FiS9i+rZb2PalTk9LlLbJF0BHE01XfTjwGeAbwALgP2BnwAn2X6yV2XcEpKOAv4VWMoLz+E/RdVP0ld1kvR6YD7Vv1c7AQtsf1bS3vRZXYaTdDTwZ7bf3a/1kXQgVSsEqkdDl9ue08f1mQL8E/Bi4GHgg5R/7xjjuiSRRERELXm0FRERtSSRRERELUkkERFRSxJJRETUkkQSERG1JJHEdk3SzztwzylliHjj+zmS/qzG/U4qs7N+b2xKuNXlWCFpn16WIfpTEknElpsCvGuzZ7XvdOCPbb91DO8Z0TVJJLHDkPTnkn4o6Z6mtUAGSmvgq2WNkO+Ut86R9MZy7iJJn5O0rMx28FngvWXNiveW2x8s6VZJD0s6a4TfP6WsdbFM0nkl9mngKODLkj437PwJkm4rv7NM0ptLfK6kQTWtaVLiKyT9j1LeQUmHS7pR0kOSPlLOObrc81pJ90n6sqRN/h6Q9D5Va6cskfSVMtnkzpIuLmVZKulPa/6RxPai19MdZ8vWyQ34efl8BzCPalLOnYBvAm+hmnJ/PTClnLcAeF/ZXwb8x7J/LmVqfuADwD80/cY5wA+AcVQzCjwBvGhYOV5J9SbxeKq3pm8BTijHbgWmtij7J4C/KPs7A7uV/b2aYrcCry/fVwBnlP3zgXuA3cpvri7xo4HnqGaH3Rm4CTix6fp9gNcB/7tRB+BLwKnAEVQzFjfKt0ev/3yzbRtbWiSxo3hH2e6mWgfkN4HJ5dgjtpeU/TuBgTIn1m62f1Dil2/m/tfbXmf7p1QT4e077PgbgVttr7G9HriMKpGN5ofAByWdA/yW7bUlfrKku0pdDqFagK2hMS/cUmCx7bW21wDPNeb5Au6w/bDtDcAVVC2iZsdQJY0flinvj6FKPA8DB0r6oqTpQN/Owhxja5deFyCiSwT8je2vbBSs1jhZ1xTaAOxK6+UERjP8HsP/29rS+2H7tjKN+XHApeXR178Cfwa80fZTki4GXtKiHM8PK9PzTWUaPi/S8O8C5tuePbxMkt4AHAucCZwMfGhL6xXbn7RIYkdxI/Chsq4JkiZKGnFRH9tPAWtVLYUL1ey2DWupHhlticXA70raR9VyzqcA/zLaBZJeRfVI6qtUMyAfTrXy3S+ApyXtS7VuxpaaVma33gl4L/D9YcdvBk5s/PNRtc73q8qIrp1sXwP891KeiLRIYsdg+zuSXgcsqmam5+fA+6haDyM5HfiqpF9Q9UU8XeLfA2aVxz5/0+bvr5I0u1wr4Abbm5vC+2jgzyX9qpT3VNuPSLobuJfqUdP/aef3h1lE1efzW8BtvDDjbaOs90n6S6qVAncCfkXVAvkl1Yp7jf8B3aTFEjumzP4bMQJJL7P987I/iywUihUAAABLSURBVGqt67N7XKxamqd773VZYvuRFknEyI4rrYhdgH+jGq0VEcOkRRIREbWksz0iImpJIomIiFqSSCIiopYkkoiIqCWJJCIiavn/3194faDLl5AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 길이 분포 출력\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_len = [len(s.split()) for s in data['Text']]\n",
    "summary_len = [len(s.split()) for s in data['Summary']]\n",
    "\n",
    "print('텍스트의 최소 길이 : {}'.format(np.min(text_len)))\n",
    "print('텍스트의 최대 길이 : {}'.format(np.max(text_len)))\n",
    "print('텍스트의 평균 길이 : {}'.format(np.mean(text_len)))\n",
    "print('요약의 최소 길이 : {}'.format(np.min(summary_len)))\n",
    "print('요약의 최대 길이 : {}'.format(np.max(summary_len)))\n",
    "print('요약의 평균 길이 : {}'.format(np.mean(summary_len)))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.boxplot(summary_len)\n",
    "plt.title('Summary')\n",
    "plt.subplot(1,2,2)\n",
    "plt.boxplot(text_len)\n",
    "plt.title('Text')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.title('Summary')\n",
    "plt.hist(summary_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "plt.title('Text')\n",
    "plt.hist(text_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_max_len = 42\n",
    "summary_max_len = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def below_threshold_len(max_len, nested_list):\n",
    "  cnt = 0\n",
    "  for s in nested_list:\n",
    "    if(len(s.split()) <= max_len):\n",
    "        cnt = cnt + 1\n",
    "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 42 이하인 샘플의 비율: 0.9750305002033347\n",
      "전체 샘플 중 길이가 12 이하인 샘플의 비율: 0.9880337535583571\n"
     ]
    }
   ],
   "source": [
    "below_threshold_len(text_max_len, data['Text'])\n",
    "below_threshold_len(summary_max_len,  data['Summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 94754\n"
     ]
    }
   ],
   "source": [
    "data = data[data['Text'].apply(lambda x: len(x.split()) <= text_max_len)]\n",
    "data = data[data['Summary'].apply(lambda x: len(x.split()) <= summary_max_len)]\n",
    "print('전체 샘플수 :',(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "      <th>decoder_input</th>\n",
       "      <th>decoder_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>upGrad learner switches to career in ML &amp; Al w...</td>\n",
       "      <td>Saurav Kant, an alumnus of upGrad and IIIT-B's...</td>\n",
       "      <td>saurav kant alumnus upgrad iiit pg program mac...</td>\n",
       "      <td>upgrad learner switches to career in ml al wit...</td>\n",
       "      <td>sostoken upgrad learner switches to career in ...</td>\n",
       "      <td>upgrad learner switches to career in ml al wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New Zealand end Rohit Sharma-led India's 12-ma...</td>\n",
       "      <td>New Zealand defeated India by 8 wickets in the...</td>\n",
       "      <td>new zealand defeated india wickets fourth odi ...</td>\n",
       "      <td>new zealand end rohit sharma led india match w...</td>\n",
       "      <td>sostoken new zealand end rohit sharma led indi...</td>\n",
       "      <td>new zealand end rohit sharma led india match w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aegon life iTerm insurance plan helps customer...</td>\n",
       "      <td>With Aegon Life iTerm Insurance plan, customer...</td>\n",
       "      <td>aegon life iterm insurance plan customers enjo...</td>\n",
       "      <td>aegon life iterm insurance plan helps customer...</td>\n",
       "      <td>sostoken aegon life iterm insurance plan helps...</td>\n",
       "      <td>aegon life iterm insurance plan helps customer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rahat Fateh Ali Khan denies getting notice for...</td>\n",
       "      <td>Pakistani singer Rahat Fateh Ali Khan has deni...</td>\n",
       "      <td>pakistani singer rahat fateh ali khan denied r...</td>\n",
       "      <td>rahat fateh ali khan denies getting notice for...</td>\n",
       "      <td>sostoken rahat fateh ali khan denies getting n...</td>\n",
       "      <td>rahat fateh ali khan denies getting notice for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>India get all out for 92, their lowest ODI tot...</td>\n",
       "      <td>India recorded their lowest ODI total in New Z...</td>\n",
       "      <td>india recorded lowest odi total new zealand ge...</td>\n",
       "      <td>india get all out for their lowest odi total i...</td>\n",
       "      <td>sostoken india get all out for their lowest od...</td>\n",
       "      <td>india get all out for their lowest odi total i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           headlines  \\\n",
       "0  upGrad learner switches to career in ML & Al w...   \n",
       "2  New Zealand end Rohit Sharma-led India's 12-ma...   \n",
       "3  Aegon life iTerm insurance plan helps customer...   \n",
       "5  Rahat Fateh Ali Khan denies getting notice for...   \n",
       "6  India get all out for 92, their lowest ODI tot...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Saurav Kant, an alumnus of upGrad and IIIT-B's...   \n",
       "2  New Zealand defeated India by 8 wickets in the...   \n",
       "3  With Aegon Life iTerm Insurance plan, customer...   \n",
       "5  Pakistani singer Rahat Fateh Ali Khan has deni...   \n",
       "6  India recorded their lowest ODI total in New Z...   \n",
       "\n",
       "                                                Text  \\\n",
       "0  saurav kant alumnus upgrad iiit pg program mac...   \n",
       "2  new zealand defeated india wickets fourth odi ...   \n",
       "3  aegon life iterm insurance plan customers enjo...   \n",
       "5  pakistani singer rahat fateh ali khan denied r...   \n",
       "6  india recorded lowest odi total new zealand ge...   \n",
       "\n",
       "                                             Summary  \\\n",
       "0  upgrad learner switches to career in ml al wit...   \n",
       "2  new zealand end rohit sharma led india match w...   \n",
       "3  aegon life iterm insurance plan helps customer...   \n",
       "5  rahat fateh ali khan denies getting notice for...   \n",
       "6  india get all out for their lowest odi total i...   \n",
       "\n",
       "                                       decoder_input  \\\n",
       "0  sostoken upgrad learner switches to career in ...   \n",
       "2  sostoken new zealand end rohit sharma led indi...   \n",
       "3  sostoken aegon life iterm insurance plan helps...   \n",
       "5  sostoken rahat fateh ali khan denies getting n...   \n",
       "6  sostoken india get all out for their lowest od...   \n",
       "\n",
       "                                      decoder_target  \n",
       "0  upgrad learner switches to career in ml al wit...  \n",
       "2  new zealand end rohit sharma led india match w...  \n",
       "3  aegon life iterm insurance plan helps customer...  \n",
       "5  rahat fateh ali khan denies getting notice for...  \n",
       "6  india get all out for their lowest odi total i...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#요약 데이터에는 시작 토큰과 종료 토큰을 추가한다.\n",
    "data['decoder_input'] = data['Summary'].apply(lambda x : 'sostoken '+ x)\n",
    "data['decoder_target'] = data['Summary'].apply(lambda x : x + ' eostoken')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = np.array(data['Text']) # 인코더의 입력\n",
    "decoder_input = np.array(data['decoder_input']) # 디코더의 입력\n",
    "decoder_target = np.array(data['decoder_target']) # 디코더의 레이블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10826  4612 50807 ... 71043 53042 16453]\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print(indices)\n",
    "\n",
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터의 수 : 18950\n"
     ]
    }
   ],
   "source": [
    "n_of_val = int(len(encoder_input)*0.2)\n",
    "print('테스트 데이터의 수 :',n_of_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 개수 : 75804\n",
      "훈련 레이블의 개수 : 75804\n",
      "테스트 데이터의 개수 : 18950\n",
      "테스트 레이블의 개수 : 18950\n"
     ]
    }
   ],
   "source": [
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :',len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :',len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :',len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 67761\n",
      "등장 빈도가 6번 이하인 희귀 단어의 수: 46089\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 21672\n",
      "단어 집합에서 희귀 단어의 비율: 68.01700092973834\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 3.5504567449866964\n"
     ]
    }
   ],
   "source": [
    "src_tokenizer = Tokenizer() # 토크나이저 정의\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 입력된 데이터로부터 단어 집합 생성\n",
    "\n",
    "threshold = 7\n",
    "total_cnt = len(src_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in src_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab = 20000\n",
    "src_tokenizer = Tokenizer(num_words = src_vocab) # 단어 집합의 크기를 8,000으로 제한\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 단어 집합 재생성."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train)\n",
    "encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[245, 569, 1927, 165, 320, 274, 2352, 1, 1927, 3389, 1440, 3335, 120, 2462, 979, 2735, 1781, 6, 1, 1927, 1258, 10021, 5307, 1580, 209, 1414, 649, 4550, 1927, 2462, 979, 390, 3896, 530, 4], [167, 19, 674, 540, 4919, 478, 5205, 11254, 23, 41, 805, 124, 195, 7459, 14473, 16269, 62, 805, 90, 54, 113, 42, 582, 520, 69, 682, 1904, 11254, 6, 23, 69, 7459, 8469, 1521, 239, 7135, 138, 6298], [894, 4141, 321, 2536, 4659, 4700, 4338, 8776, 918, 557, 5667, 3442, 345, 2022, 3390, 413, 5166, 369, 375, 42, 193, 844, 12, 3317, 894, 4701, 1, 722, 4523, 5667, 557, 40, 986, 293, 194, 295]]\n"
     ]
    }
   ],
   "source": [
    "#잘 진행되었는지 샘플 출력\n",
    "print(encoder_input_train[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_tokenizer = Tokenizer()\n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 29566\n",
      "등장 빈도가 5번 이하인 희귀 단어의 수: 19350\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 10216\n",
      "단어 집합에서 희귀 단어의 비율: 65.44679699655009\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 4.778565426687958\n"
     ]
    }
   ],
   "source": [
    "threshold = 6\n",
    "total_cnt = len(tar_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tar_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\n",
      "input  [[1, 1379, 10, 4270, 4, 1829, 1941, 2040], [1, 3602, 4730, 773, 458, 69, 5, 2203, 6, 34], [1, 584, 2652, 1676, 41, 2457, 9324], [1, 4731, 2653, 7, 85, 9, 323, 3328, 2414], [1, 399, 2502, 109, 6669, 158, 4, 18, 28, 34]]\n",
      "target\n",
      "decoder  [[1379, 10, 4270, 4, 1829, 1941, 2040, 2], [3602, 4730, 773, 458, 69, 5, 2203, 6, 34, 2], [584, 2652, 1676, 41, 2457, 9324, 2], [4731, 2653, 7, 85, 9, 323, 3328, 2414, 2], [399, 2502, 109, 6669, 158, 4, 18, 28, 34, 2]]\n"
     ]
    }
   ],
   "source": [
    "tar_vocab = 10000\n",
    "tar_tokenizer = Tokenizer(num_words = tar_vocab) \n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "tar_tokenizer.fit_on_texts(decoder_target_train)\n",
    "\n",
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train) \n",
    "decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n",
    "decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n",
    "decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)\n",
    "\n",
    "#잘 변환되었는지 확인\n",
    "print('input')\n",
    "print('input ',decoder_input_train[:5])\n",
    "print('target')\n",
    "print('decoder ',decoder_target_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삭제할 훈련 데이터의 개수 : 0\n",
      "삭제할 테스트 데이터의 개수 : 1\n",
      "훈련 데이터의 개수 : 75804\n",
      "훈련 레이블의 개수 : 75804\n",
      "테스트 데이터의 개수 : 18949\n",
      "테스트 레이블의 개수 : 18949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "drop_train = [index for index, sentence in enumerate(decoder_input_train) if len(sentence) == 1]\n",
    "drop_test = [index for index, sentence in enumerate(decoder_input_test) if len(sentence) == 1]\n",
    "\n",
    "print('삭제할 훈련 데이터의 개수 :',len(drop_train))\n",
    "print('삭제할 테스트 데이터의 개수 :',len(drop_test))\n",
    "\n",
    "encoder_input_train = np.delete(encoder_input_train, drop_train, axis=0)\n",
    "decoder_input_train = np.delete(decoder_input_train, drop_train, axis=0)\n",
    "decoder_target_train = np.delete(decoder_target_train, drop_train, axis=0)\n",
    "\n",
    "encoder_input_test = np.delete(encoder_input_test, drop_test, axis=0)\n",
    "decoder_input_test = np.delete(decoder_input_test, drop_test, axis=0)\n",
    "decoder_target_test = np.delete(decoder_target_test, drop_test, axis=0)\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :',len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :',len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :',len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_train = pad_sequences(encoder_input_train, maxlen = text_max_len, padding='post')\n",
    "encoder_input_test = pad_sequences(encoder_input_test, maxlen = text_max_len, padding='post')\n",
    "decoder_input_train = pad_sequences(decoder_input_train, maxlen = summary_max_len, padding='post')\n",
    "decoder_target_train = pad_sequences(decoder_target_train, maxlen = summary_max_len, padding='post')\n",
    "decoder_input_test = pad_sequences(decoder_input_test, maxlen = summary_max_len, padding='post')\n",
    "decoder_target_test = pad_sequences(decoder_target_test, maxlen = summary_max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "# 인코더 설계 시작\n",
    "embedding_dim = 128\n",
    "hidden_size = 256\n",
    "\n",
    "# 인코더\n",
    "encoder_inputs = Input(shape=(text_max_len,))\n",
    "\n",
    "# 인코더의 임베딩 층\n",
    "enc_emb = Embedding(src_vocab, embedding_dim)(encoder_inputs)\n",
    "\n",
    "# 인코더의 LSTM 1\n",
    "encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4, recurrent_dropout = 0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "# 인코더의 LSTM 2\n",
    "encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "# 인코더의 LSTM 3\n",
    "encoder_lstm3 = LSTM(hidden_size, return_state=True, return_sequences=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "# 디코더 설계\n",
    "\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "# 디코더의 임베딩 층\n",
    "dec_emb_layer = Embedding(tar_vocab, embedding_dim)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 디코더의 LSTM\n",
    "decoder_lstm = LSTM(hidden_size, return_sequences = True, return_state = True, dropout = 0.4, recurrent_dropout=0.2)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state = [state_h, state_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 42)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 42, 128)      2560000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 42, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 42, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    1280000     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 42, 256), (N 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 256),  394240      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 10000)  2570000     lstm_3[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 8,249,104\n",
      "Trainable params: 8,249,104\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation = 'softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_outputs) \n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/thushv89/attention_keras/master/src/layers/attention.py\", filename=\"attention.py\")\n",
    "from attention import AttentionLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 42)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 42, 128)      2560000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 42, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 42, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    1280000     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 42, 256), (N 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 256),  394240      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 256),  131328      lstm_2[0][0]                     \n",
      "                                                                 lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 512)    0           lstm_3[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 10000)  5130000     concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 10,940,432\n",
      "Trainable params: 10,940,432\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 어텐션 층(어텐션 함수)\n",
    "attn_layer = AttentionLayer(name='attention_layer')\n",
    "# 인코더와 디코더의 모든 time step의 hidden state를 어텐션 층에 전달하고 결과를 리턴\n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
    "\n",
    "# 어텐션의 결과와 디코더의 hidden state들을 연결\n",
    "decoder_concat_input = Concatenate(axis = -1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_concat_input)\n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "297/297 [==============================] - 94s 317ms/step - loss: 5.6244 - val_loss: 5.2259\n",
      "Epoch 2/50\n",
      "297/297 [==============================] - 94s 316ms/step - loss: 5.0610 - val_loss: 4.8271\n",
      "Epoch 3/50\n",
      "297/297 [==============================] - 93s 312ms/step - loss: 4.7056 - val_loss: 4.5790\n",
      "Epoch 4/50\n",
      "297/297 [==============================] - 94s 317ms/step - loss: 4.4396 - val_loss: 4.4068\n",
      "Epoch 5/50\n",
      "297/297 [==============================] - 92s 310ms/step - loss: 4.2310 - val_loss: 4.2401\n",
      "Epoch 6/50\n",
      "297/297 [==============================] - 92s 311ms/step - loss: 4.0585 - val_loss: 4.1262\n",
      "Epoch 7/50\n",
      "297/297 [==============================] - 92s 311ms/step - loss: 3.9094 - val_loss: 4.0384\n",
      "Epoch 8/50\n",
      "297/297 [==============================] - 92s 311ms/step - loss: 3.7827 - val_loss: 3.9504\n",
      "Epoch 9/50\n",
      "297/297 [==============================] - 92s 311ms/step - loss: 3.6730 - val_loss: 3.8904\n",
      "Epoch 10/50\n",
      "297/297 [==============================] - 93s 315ms/step - loss: 3.5732 - val_loss: 3.8364\n",
      "Epoch 11/50\n",
      "297/297 [==============================] - 93s 312ms/step - loss: 3.4848 - val_loss: 3.8072\n",
      "Epoch 12/50\n",
      "297/297 [==============================] - 99s 333ms/step - loss: 3.4060 - val_loss: 3.7577\n",
      "Epoch 13/50\n",
      "297/297 [==============================] - 99s 332ms/step - loss: 3.3352 - val_loss: 3.7290\n",
      "Epoch 14/50\n",
      "297/297 [==============================] - 94s 318ms/step - loss: 3.2660 - val_loss: 3.6934\n",
      "Epoch 15/50\n",
      "297/297 [==============================] - 97s 328ms/step - loss: 3.2037 - val_loss: 3.6688\n",
      "Epoch 16/50\n",
      "297/297 [==============================] - 93s 313ms/step - loss: 3.1465 - val_loss: 3.6517\n",
      "Epoch 17/50\n",
      "297/297 [==============================] - 92s 311ms/step - loss: 3.0957 - val_loss: 3.6322\n",
      "Epoch 18/50\n",
      "297/297 [==============================] - 91s 305ms/step - loss: 3.0490 - val_loss: 3.6187\n",
      "Epoch 19/50\n",
      "297/297 [==============================] - 92s 309ms/step - loss: 3.0017 - val_loss: 3.6084\n",
      "Epoch 20/50\n",
      "297/297 [==============================] - 92s 310ms/step - loss: 2.9585 - val_loss: 3.6006\n",
      "Epoch 21/50\n",
      "297/297 [==============================] - 92s 311ms/step - loss: 2.9181 - val_loss: 3.5831\n",
      "Epoch 22/50\n",
      "297/297 [==============================] - 93s 312ms/step - loss: 2.8758 - val_loss: 3.5811\n",
      "Epoch 23/50\n",
      "297/297 [==============================] - 92s 308ms/step - loss: 2.8397 - val_loss: 3.5801\n",
      "Epoch 24/50\n",
      "297/297 [==============================] - 90s 304ms/step - loss: 2.8039 - val_loss: 3.5575\n",
      "Epoch 25/50\n",
      "297/297 [==============================] - 92s 309ms/step - loss: 2.7685 - val_loss: 3.5681\n",
      "Epoch 26/50\n",
      "297/297 [==============================] - 92s 310ms/step - loss: 2.7362 - val_loss: 3.5662\n",
      "Epoch 00026: early stopping\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 2)\n",
    "history = model.fit(x = [encoder_input_train, decoder_input_train], y = decoder_target_train, \\\n",
    "          validation_data = ([encoder_input_test, decoder_input_test], decoder_target_test),\n",
    "          batch_size = 256, callbacks=[es], epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_index_to_word = src_tokenizer.index_word # 원문 단어 집합에서 정수 -> 단어를 얻음\n",
    "tar_word_to_index = tar_tokenizer.word_index # 요약 단어 집합에서 단어 -> 정수를 얻음\n",
    "tar_index_to_word = tar_tokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 설계\n",
    "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# 이전 시점의 상태들을 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(hidden_size,))\n",
    "decoder_state_input_c = Input(shape=(hidden_size,))\n",
    "\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n",
    "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어텐션 함수\n",
    "decoder_hidden_state_input = Input(shape=(text_max_len, hidden_size))\n",
    "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_outputs2 = decoder_softmax_layer(decoder_inf_concat) \n",
    "\n",
    "# 최종 디코더 모델\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "     # <SOS>에 해당하는 토큰 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = tar_word_to_index['sostoken']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition: # stop_condition이 True가 될 때까지 루프 반복\n",
    "\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = tar_index_to_word[sampled_token_index]\n",
    "\n",
    "        if(sampled_token!='eostoken'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        #  <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_token == 'eostoken'  or len(decoded_sentence.split()) >= (summary_max_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 길이가 1인 타겟 시퀀스를 업데이트\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 상태를 업데이트 합니다.\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2text(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            temp = temp + src_index_to_word[i]+' '\n",
    "    return temp\n",
    "\n",
    "# 요약문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2summary(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=tar_word_to_index['sostoken']) and i!=tar_word_to_index['eostoken']):\n",
    "            temp = temp + tar_index_to_word[i] + ' '\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원문 : passengers jet airways flight tuesday night protested runway delhi airport flight cancelled passengers sat runway alleged harassment claimed flight kept delayed finally cancelled video protest also emerged \n",
      "실제 요약 : flyers protest on airport runway after flight is cancelled \n",
      "예측 요약 :  jet airways flight suspended after being hit by\n",
      "\n",
      "\n",
      "원문 : ibm developed ai based wearable sensor prototype help monitor human health wireless device uses array strain detect users grip strength conducting tasks like opening jar writing sends data smartwatch uses machine learning detect symptoms diseases like \n",
      "실제 요약 : ibm makes sensor prototype to track users health \n",
      "예측 요약 :  smart which that can detect smartphone made\n",
      "\n",
      "\n",
      "원문 : passenger took shirt attacked ground crew forced leave american airlines flight us airport passenger reportedly behaving manner asked police called began yelling throwing things tarmac \n",
      "실제 요약 : man kicked off flight takes off shirt attacks crew \n",
      "예측 요약 :  man who was drunk man who was drunk man on flight\n",
      "\n",
      "\n",
      "원문 : oneplus crossed million unit sales within days launch becoming fastest selling oneplus smartphone since inception company oneplus revealed million strong global community also announced community celebration season display gratitude community running offers june \n",
      "실제 요약 : oneplus global sales cross million units within days \n",
      "예측 요약 :  oneplus to become nd most valuable firm in the world\n",
      "\n",
      "\n",
      "원문 : former gwalior mayor bjp leader gupta tuesday announced quit party contesting assembly elections madhya pradesh independently dedicated party workers ignored resigned party said gupta already filed nomination gwalior independent candidate \n",
      "실제 요약 : former mayor gupta quits bjp \n",
      "예측 요약 :  former bjp leader quits party for party leader quits\n",
      "\n",
      "\n",
      "원문 : india ankit forgot take one gloves going bat india deodhar trophy match thursday adjusted right hand glove walking middle suddenly realised forgot bring went back get left hand glove getting golden duck \n",
      "실제 요약 : india batsman comes out to bat wearing just one \n",
      "예측 요약 :  india goes viral after hitting runs on field\n",
      "\n",
      "\n",
      "원문 : delhi high court observed woman slapping husband front others amount instigating husband commit suicide court gave order discharging woman alleged offence driving husband commit suicide slapping deceased father claimed killed embarrassed \n",
      "실제 요약 : wife slapping man not to commit suicide delhi hc \n",
      "예측 요약 :  woman claims woman to marry woman in delhi court\n",
      "\n",
      "\n",
      "원문 : microsoft recently launched virtual assistant accelerator promises develop bots enhance personalised content delivery across multiple devices talking technology world ai show microsoft said unlocking power ai human develop overall national capabilities economy \n",
      "실제 요약 : microsoft launches virtual assistant accelerator \n",
      "예측 요약 :  microsoft launches tv tv channels for the\n",
      "\n",
      "\n",
      "원문 : tweet fan explaining rcb make ipl playoffs despite losing seven first matches gone viral per user rcb still qualify playoffs without even net run rate reacting tweet user wrote tell rcb win ipl \n",
      "실제 요약 : fan tweet how rcb can still qualify goes viral \n",
      "예측 요약 :  fan fan fan to miss ipl final after losing points\n",
      "\n",
      "\n",
      "원문 : former environment minister jairam ramesh sunday rejected reports claiming role granting clearance sterlite copper plant tuticorin said became environment minister may sterlite project received three rounds clearances march january claimed facts deliberately distorted question role \n",
      "실제 요약 : no role in giving clearance to sterlite plan ex minister \n",
      "예측 요약 :  govt rejects govt to release in sterlite protests\n",
      "\n",
      "\n",
      "원문 : marcus rashford extra time goal sent manchester united europa league semi finals following win old trafford thursday th minute opener cancelled nd minute taking game extra time united advanced aggregate playing draw first leg \n",
      "실제 요약 : goal takes manchester utd to europa league semis \n",
      "예측 요약 :  arsenal beat arsenal to win their th straight win\n",
      "\n",
      "\n",
      "원문 : england based grocery store chain looking hire chicken ahead launch new range frozen fresh foods job description says employee able eat mcdonald chicken nuggets first office kitchen whenever someone says cake \n",
      "실제 요약 : firm looks to hire employee who can eat chicken \n",
      "예측 요약 :  startup to shut down after stores\n",
      "\n",
      "\n",
      "원문 : slamming pm narendra modi remaining silent mob lynching incidents aap mp sanjay singh asked bjp want turn country taliban state government shielding accused lynching incidents added comes union minister arjun ram meghwal claimed incidents lynching increase rise pm modi popularity \n",
      "실제 요약 : does bjp want to convert india into taliban state asks aap \n",
      "예측 요약 :  pm modi slams bjp for calling him terrorists\n",
      "\n",
      "\n",
      "원문 : social media giant facebook wednesday posted year year increase profit billion september quarter company also reported increase revenue billion invested money advertising offerings facebook billion monthly active users compared period last year \n",
      "실제 요약 : facebook profit rises to billion in sept quarter \n",
      "예측 요약 :  facebook profit rises to billion in sept quarter\n",
      "\n",
      "\n",
      "원문 : force india deputy team principal robert said vijay mallya track troubles impacted force india said mallya cannot travel remains involved ever functioning team never one man show everyone team assigned job performing rather well added \n",
      "실제 요약 : mallya cannot travel but part of team force india \n",
      "예측 요약 :  indians should not get back india extradition india\n",
      "\n",
      "\n",
      "원문 : housefull producer sajid nadiadwala confirmed nana patekar star film earlier reports nana replacing sanjay dutt film dutt hiked fee post success biopic sanju refuting nadiadwala said approached dutt housefull adding nana signed sanju release \n",
      "실제 요약 : nana patekar to star in housefull \n",
      "예측 요약 :  housefull to star in housefull reports\n",
      "\n",
      "\n",
      "원문 : garment project provides clothing women recovering eating disorder free goal give clients wardrobe new clothing get first six months recovery process founded lived eating disorder years \n",
      "실제 요약 : women recovering from eating disorder given free clothes \n",
      "예측 요약 :  startup makes clothes that can be made\n",
      "\n",
      "\n",
      "원문 : facebook sought time indian government determine extent security breach affected indian users ministry electronics information technology asked social media giant impact users india last week facebook reported security breach compromised data million accounts \n",
      "실제 요약 : fb seeks more time to study breach impact on indian users \n",
      "예측 요약 :  facebook asks indian to block data accounts\n",
      "\n",
      "\n",
      "원문 : haryana cm manohar lal khattar deferred government notification directed sportspersons employed state pay income sports council added athletes pay entire income considered duty government notification put hold several sportspersons slammed \n",
      "실제 요약 : yana cm stops order on players paying income post backlash \n",
      "예측 요약 :  haryana govt to pay yana for mlas to mlas\n",
      "\n",
      "\n",
      "원문 : american civil liberties union monday filed lawsuit challenging us president donald trump ban transgender people serving military lawsuit alleges ban discriminatory violates equal protection clause us constitution filed behalf six transgender members serving military \n",
      "실제 요약 : donald trump sued over transgender military ban \n",
      "예측 요약 :  us court allows trump to ban on immigrants\n",
      "\n",
      "\n",
      "원문 : though government slashed excise duty petrol diesel union budget fuel prices remained unchanged due introduction road infrastructure cess basic excise duty fuels cut per litre additional excise duty road infrastructure cess added burden per litre \n",
      "실제 요약 : fuel prices remain unchanged excise duty cut by \n",
      "예측 요약 :  petrol diesel prices cut by litre diesel by litre\n",
      "\n",
      "\n",
      "원문 : video pakistan prime minister waiting imran khan borrowing photographer national assembly card picture gone viral video photographer seen taking black helping khan wear khan took oath member national assembly outgoing speaker sadiq monday \n",
      "실제 요약 : video imran khan for official photo \n",
      "예측 요약 :  pak pm imran khan asks pm to wear helmet on pic\n",
      "\n",
      "\n",
      "원문 : doklam standoff reportedly stalled survey india plans mount everest collaboration nepalese authorities wanted eliminate doubts raised international scientific community earthquake april could changed height peak however still awaiting nod nepalese side plan \n",
      "실제 요약 : doklam standoff stalls plan to everest height \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 요약 :  china to build india highest of nepal road\n",
      "\n",
      "\n",
      "원문 : liu china recently proposed girlfriend meteorite claims bought around lakh meteorite reportedly weighed ton hidden red cover square revealed friends girlfriend said yes liu stated space rock stable marriage \n",
      "실제 요약 : man proposes to girlfriend with meteorite worth lakh \n",
      "예측 요약 :  chinese firm accused of copying daughter worth lakh\n",
      "\n",
      "\n",
      "원문 : former russian spy sergei skripal daughter yulia said fact father attacked using nerve agent turned world upside physically emotionally added lucky survived attempted assassination longer term hope return home country yulia said \n",
      "실제 요약 : attempted murder turned world upside down ex spy daughter \n",
      "예측 요약 :  father raped by mother of daughter ex spy spy daughter\n",
      "\n",
      "\n",
      "원문 : former bcci president anurag thakur asked supreme court make public names players allegedly named ipl spot fixing scandal names submitted sc february sealed envelope never opened sc let lodha committee decide feasibility opening envelope \n",
      "실제 요약 : ex bcci prez asks sc to reveal names of ipl spot \n",
      "예측 요약 :  bcci to ban sc over bcci chief controversy\n",
      "\n",
      "\n",
      "원문 : pornstar stormy daniels monday sued us president donald trump defamatory tweet lawsuit alleges trump attempted tarnish daniels reputation dismissing description man threatened remain silent alleged affair us president claimed pornstar suffered damages exceeding \n",
      "실제 요약 : pornstar sues trump over tweet \n",
      "예측 요약 :  pornstar sues trump for calling her silence on twitter\n",
      "\n",
      "\n",
      "원문 : petition filed delhi high court seeking ban trailer upcoming film accidental prime minister plea claims film image former pm manmohan singh facts petition earlier filed lawyer bihar anupam kher associated members film \n",
      "실제 요약 : plea in delhi hc seeks ban on trailer of the accidental \n",
      "예측 요약 :  court rejects plea against sanjay dutt biopic on release\n",
      "\n",
      "\n",
      "원문 : least three soldiers including officer martyred apparent suicide attack terrorists army camp kashmir kupwara district thursday morning two militants killed retaliation forces two others reportedly believed still inside camp five injured jawans airlifted srinagar treatment \n",
      "실제 요약 : soldiers martyred in terror attack on army camp in kashmir \n",
      "예측 요약 :  taliban attack on afghan soldiers killed in\n",
      "\n",
      "\n",
      "원문 : lok sabha passed muslim women bill following debate bill proposes make method muslim men instantly wives talaq thrice unconstitutional arbitrary suggests three year jail term husbands follow method presented rajya sabha \n",
      "실제 요약 : lok sabha passes bill to make instant triple talaq criminal offence \n",
      "예측 요약 :  bill to allow women to triple talaq bill\n",
      "\n",
      "\n",
      "원문 : picture us president donald trump pope francis first meeting vatican surfaced online twitter erupted memes jokes pointing pope apparent unhappy expression one memes featured two leaders along characters conjuring shining others showed trump pope \n",
      "실제 요약 : twitter erupts with jokes memes after trump pope first meet \n",
      "예측 요약 :  trump slams trump for his speech at his word\n",
      "\n",
      "\n",
      "원문 : rohit sharma led india asia cup victory said captaincy style similar ms dhoni whatever seen dhoni leading years never panicked took time taking decisions similarities said always keep learning dhoni amazing captain rohit added \n",
      "실제 요약 : my style of captaincy is similar to that of dhoni rohit sharma \n",
      "예측 요약 :  dhoni shaw is great dhoni in india rohit shetty\n",
      "\n",
      "\n",
      "원문 : school kolkata accused ten female students leading protests parents school authorities said received complaints students upon confrontation girls admitted asked submit writing however parents alleged school authorities forcibly obtained written admission girls \n",
      "실제 요약 : parents protest after school accuses girls of being \n",
      "예측 요약 :  students asked to allow girls to school girls in school\n",
      "\n",
      "\n",
      "원문 : prime minister narendra modi asked tax officials friendly honest taxpayers bid make india tax compliant society also asked ensure benefits gst biggest tax reform since independence reach common man way reduced prices modi appreciated tax officials efforts smooth gst implementation \n",
      "실제 요약 : be friendly to honest taxpayers pm modi to tax officials \n",
      "예측 요약 :  pm modi to launch gst on gst evasion\n",
      "\n",
      "\n",
      "원문 : delhi chief minister aap convener arvind kejriwal thursday met actor kamal haasan expected join politics soon chennai tamil nadu kejriwal received airport haasan younger daughter kejriwal national profile fighting corruption dialogue united haasan said \n",
      "실제 요약 : delhi cm arvind kejriwal meets kamal haasan in chennai \n",
      "예측 요약 :  kejriwal meets rajinikanth plea on toilet ek prem katha\n",
      "\n",
      "\n",
      "원문 : reacting indian opener rohit sharma slamming third odi double hundred user tweeted incredible week tweets read rohit sharma nd indian scare sri core first hanuman common wolf rohit sharma surprise opponents least expect \n",
      "실제 요약 : an incredible week for tweets user on rohit \n",
      "예측 요약 :  rohit sharma trolls rohit sharma for his odi series\n",
      "\n",
      "\n",
      "원문 : talking fashion sense kajol said think people take inspiration comes fashion started films time form opinion style added kajol said idea suits \n",
      "실제 요약 : should not take inspiration from me fashion kajol \n",
      "예측 요약 :  am not just just because of doing that am kajol\n",
      "\n",
      "\n",
      "원문 : chhattisgarh primary school teacher arrested allegedly stealing two designer saris worth wife wear local beauty pageant police said gupta admitted could afford saris want wife feel among women community gupta reportedly earns per month \n",
      "실제 요약 : man steals designer for wife to wear at beauty pageant \n",
      "예측 요약 :  teacher held for selling fake sex with obscene pics\n",
      "\n",
      "\n",
      "원문 : nissan monday said recalling million cars japan meet domestic rules final safety inspections announcement came nissan shares slumped reports tests performed staff certified check vehicles per government standards affected vehicles built october september \n",
      "실제 요약 : nissan recalls million cars in japan on safety \n",
      "예측 요약 :  nissan to cut cars to volkswagen in us\n",
      "\n",
      "\n",
      "원문 : talking advances artificial intelligence microsoft ceo satya nadella said company going infuse everything ai also said going perception capability language capability autonomy going built applications going forward self driving projects autonomy everywhere nadella added \n",
      "실제 요약 : microsoft will everything with ai ceo satya nadella \n",
      "예측 요약 :  ai to work with ai to mars on mars ceo\n",
      "\n",
      "\n",
      "원문 : hollywood filmmaker bryan singer known directing men films denied allegations sexually harassed year old boy victim named sanchez guzman alleged singer forced sexual acts yacht party sanchez guzman seeking compensation damages well past future medical expenses legal costs \n",
      "실제 요약 : director bryan singer denies sexually assaulting yr old \n",
      "예측 요약 :  oscar winning director accused of sexual assault victim\n",
      "\n",
      "\n",
      "원문 : malayalam actress priya prakash varrier became popular clip showing winking song manikya poovi went viral paid around crore television commercial per reports year old girl also reportedly charging lakh per post social media accounts \n",
      "실제 요약 : priya whose wink clip went viral got cr for ad reports \n",
      "예측 요약 :  malayalam actor priya becomes most followed in us\n",
      "\n",
      "\n",
      "원문 : talking management style infosys ceo salil parekh said spends much time talking staff customers like second hand information said get details micro manager earlier january parekh said immediate priorities would include connecting employees clients build roadmap future \n",
      "실제 요약 : do not like second hand info infosys ceo on management style \n",
      "예측 요약 :  we will not take back to shut down infosys ceo\n",
      "\n",
      "\n",
      "원문 : gujarat cm vijay rupani sunday said government violence name gau raksha action would taken responsible talking recent reports violence dalits state rupani said action immediately taken cases government ensuring safety community \n",
      "실제 요약 : we are against violence in name of gau raksha gujarat cm \n",
      "예측 요약 :  gujarat cm blames bjp for not naxals\n",
      "\n",
      "\n",
      "원문 : president moreno ordered immediate removal extra security assigned wikileaks founder julian assange country embassy london move comes guardian revealed ecuador spent nearly crore surveillance operation protect assange embassy assange seeking political asylum ecuadorian embassy london since \n",
      "실제 요약 : ecuador orders to remove assange extra security at embassy \n",
      "예측 요약 :  wikileaks suspends assange over anti anti protests\n",
      "\n",
      "\n",
      "원문 : india pakistan asia cup match sunday rohit sharma shikhar dhawan shared opening partnership runs set record highest opening partnership india pakistan odi cricket duo broke previous record runs set sachin tendulkar sourav ganguly dhaka january \n",
      "실제 요약 : rohit dhawan share run stand vs pak break year old record \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 요약 :  india beat sl to become highest odi ton in odis\n",
      "\n",
      "\n",
      "원문 : state run telecom firm bsnl signed deal japan softbank communications launch internet service internet things technology india bsnl chairman anupam shrivastava said agreement look solution specially smart cities added also said service may launch country \n",
      "실제 요약 : bsnl signs deal with softbank to roll out in india \n",
      "예측 요약 :  to invest bn in acquisition of\n",
      "\n",
      "\n",
      "원문 : tamil nadu chief minister palaniswami met prime minister narendra modi delhi friday meeting lasted around minutes reportedly gave brief merger talks aiadmk faction led former cm panneerselvam according reports bjp urged two factions merge join ruling nda \n",
      "실제 요약 : tamil nadu cm meets pm modi amid merger talks \n",
      "예측 요약 :  pm modi meets tn cm over pm modi visit\n",
      "\n",
      "\n",
      "원문 : china billionaire entrepreneur commerce major alibaba co founder jack said malaysia current pm mahathir bin mohamad inspired start alibaba years ago said one day reading newspaper saw multimedia super corridor said malaysia could could china added thank mahathir great inspiration \n",
      "실제 요약 : was inspired by malaysia pm to start alibaba yrs ago jack ma \n",
      "예측 요약 :  alibaba founder jack ma to japan billionaire\n",
      "\n",
      "\n",
      "원문 : former uttar pradesh cms mulayam singh yadav akhilesh yadav thursday vacated official residences lucknow compliance supreme court order comes father son duo moved apex court seeking appropriate time vacate residential accommodation sc earlier month said former cms cannot live government accommodations stepping \n",
      "실제 요약 : ex up cms mulayam akhilesh vacate government \n",
      "예측 요약 :  verdict akhilesh seeks son for sc st time in ayodhya case\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "for i in range(50, 100):\n",
    "    print(\"원문 :\", seq2text(encoder_input_test[i]))\n",
    "    print(\"실제 요약 :\", seq2summary(decoder_input_test[i]))\n",
    "    print(\"예측 요약 :\", decode_sequence(encoder_input_test[i].reshape(1, text_max_len)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text= Saurav Kant, an alumnus of upGrad and IIIT-B's PG Program in Machine learning and Artificial Intelligence, was a Sr Systems Engineer at Infosys with almost 5 years of work experience. The program and upGrad's 360-degree career support helped him transition to a Data Scientist at Tech Mahindra with 90% salary hike. upGrad's Online Power Learning has powered 3 lakh+ careers.\n",
      "Summary:\n",
      "upGrad's Online Power Learning has powered 3 lakh+ careers.\n",
      "Summary:\n",
      "The program and upGrad's 360-degree career support helped him transition to a Data Scientist at Tech Mahindra with 90% salary hike.\n",
      "upGrad's Online Power Learning has powered 3 lakh+ careers.\n",
      "Headlin:\n",
      "upGrad learner switches to career in ML & Al with 90% salary hike\n",
      "\n",
      "\n",
      "text= Kunal Shah's credit card bill payment platform, CRED, gave users a chance to win free food from Swiggy for one year. Pranav Kaushik, a Delhi techie, bagged this reward after spending 2000 CRED coins. Users get one CRED coin per rupee of bill paid, which can be used to avail rewards from brands like Ixigo, BookMyShow, UberEats, Cult.Fit and more.\n",
      "Summary:\n",
      "Users get one CRED coin per rupee of bill paid, which can be used to avail rewards from brands like Ixigo, BookMyShow, UberEats, Cult.Fit and more.\n",
      "Summary:\n",
      "Users get one CRED coin per rupee of bill paid, which can be used to avail rewards from brands like Ixigo, BookMyShow, UberEats, Cult.Fit and more.\n",
      "Headlin:\n",
      "Delhi techie wins free food from Swiggy for one year on CRED\n",
      "\n",
      "\n",
      "text= New Zealand defeated India by 8 wickets in the fourth ODI at Hamilton on Thursday to win their first match of the five-match ODI series. India lost an international match under Rohit Sharma's captaincy after 12 consecutive victories dating back to March 2018. The match witnessed India getting all out for 92, their seventh lowest total in ODI cricket history.\n",
      "Summary:\n",
      "The match witnessed India getting all out for 92, their seventh lowest total in ODI cricket history.\n",
      "Summary:\n",
      "The match witnessed India getting all out for 92, their seventh lowest total in ODI cricket history.\n",
      "Headlin:\n",
      "New Zealand end Rohit Sharma-led India's 12-match winning streak\n",
      "\n",
      "\n",
      "text= With Aegon Life iTerm Insurance plan, customers can enjoy tax benefits on your premiums paid and save up to Ã¢ÂÂ¹46,800^ on taxes. The plan provides life cover up to the age of 100 years. Also, customers have options to insure against Critical Illnesses, Disability and Accidental Death Benefit Rider with a life cover up to the age of 80 years.\n",
      "Summary:\n",
      "Also, customers have options to insure against Critical Illnesses, Disability and Accidental Death Benefit Rider with a life cover up to the age of 80 years.\n",
      "Summary:\n",
      "Also, customers have options to insure against Critical Illnesses, Disability and Accidental Death Benefit Rider with a life cover up to the age of 80 years.\n",
      "Headlin:\n",
      "Aegon life iTerm insurance plan helps customers save tax\n",
      "\n",
      "\n",
      "text= Speaking about the sexual harassment allegations against Rajkumar Hirani, Sonam Kapoor said, \"I've known Hirani for many years...What if it's not true, the [#MeToo] movement will get derailed.\" \"In the #MeToo movement, I always believe a woman. But in this case, we need to reserve our judgment,\" she added. Hirani has been accused by an assistant who worked in 'Sanju'.\n",
      "Summary:\n",
      "Speaking about the sexual harassment allegations against Rajkumar Hirani, Sonam Kapoor said, \"I've known Hirani for many years...What if it's not true, the [#MeToo] movement will get derailed.\" \"In the #MeToo movement, I always believe a woman.\n",
      "Summary:\n",
      "Speaking about the sexual harassment allegations against Rajkumar Hirani, Sonam Kapoor said, \"I've known Hirani for many years...What if it's not true, the [#MeToo] movement will get derailed.\" \"In the #MeToo movement, I always believe a woman.\n",
      "Headlin:\n",
      "Have known Hirani for yrs, what if MeToo claims are not true: Sonam\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from summa.summarizer import summarize\n",
    "pd_data = pd.read_csv('news_summary_more.csv', encoding='iso-8859-1')\n",
    "text = pd_data.text.values.tolist()\n",
    "headlines = pd_data.headlines.values.tolist()\n",
    "for i in range(5):\n",
    "    print(\"text=\",text[i])\n",
    "    print('Summary:')\n",
    "    print(summarize(text[i], ratio=0.5))\n",
    "    print('Summary:')\n",
    "    print(summarize(text[i], words=20))\n",
    "    print('Headlin:')\n",
    "    print(headlines[i])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 네트워크 구조를 변경하지 않아 정확도가 높진 않은 것 같다. train loss는 지속적으로 줄어드는게 보이지만 validation loss는 학습초기에만 줄어들고 그 다음에는 크게 변동이 없다. summa를 사용한 결과는 text내에 존재하는 단어만을 사용하기 때문에 Headline에서만 보이는 단어의 경우는 나타내지 못한다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
