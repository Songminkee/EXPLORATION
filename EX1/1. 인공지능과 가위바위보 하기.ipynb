{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST DATASET DOWNLOAD\n",
    "간단한 학습예제 전에 tensorflow가 제대로 설치되어 있는지, 버전이 몇인지 체크를 하기 위해 다음과 같이 작성한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "%matplotlib inline\n",
    "print(tf.__version__) # Tensorflow의 버전을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST 데이터의 경우 keras의 dataset을 사용해 쉽게 다운로드 할 수 있다. 작성은 다음과 같다. 경로에 이미 설치된 동일 dataset이 있는 경우 다시 다운로드를 하진 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = keras.datasets.mnist\n",
    "\n",
    "# MNIST 데이터 로드 or 다운로드\n",
    "(x_train, y_train),(x_test,y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "len함수를 사용하면 데이터의 길이를 확인 할 수 있다. 다음과 같이 작성하면 각각의 데이터의 길이를 볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train))\n",
    "print(len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "len함수의 경우 데이터의 첫 번째 차원에 대한 길이만 확인 할 수 있다.\n",
    "반면, 다음과 같이 작성하면 이미지의 전체 shape을 확인 할 수 있다.\n",
    "x_train과 x_test는 입력 이미지 데이터이다.\n",
    "shape을 보면 3가지를 확인 할 수 있는데 각각 (개수,높이,너비)를 나타내며 각각은 해당하는 픽셀의 값을 나타낸다.\n",
    "y_train과 y_test는 정답 label이고 숫자가 몇 인지 나타내기 때문에 하나의 값이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = random.randint(0,len(x_train))\n",
    "plt.imshow(x_train[index],cmap='gray')\n",
    "plt.xlabel(\"Number of {} index is {}\".format(index,y_train[index]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "현재 다운로드 받은 이미지 데이터는 0\\~255값을 갖는데 딥러닝에서 layer를 거침에 따라 1이상의 값은 지수적으로 값이 증폭되기 때문에 0\\~1의 값을 사용하는게 보통이다.\n",
    "다음과 In[9]와 같이 작성하면 0\\~1 값으로 정규화 할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최소값: 0  최대값: 255\n"
     ]
    }
   ],
   "source": [
    "print('최소값:',np.min(x_train), ' 최대값:',np.max(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최소값: 0.0  최대값: 1.0\n"
     ]
    }
   ],
   "source": [
    "x_train_norm, x_test_norm = x_train / 255.0, x_test / 255.0\n",
    "print('최소값:',np.min(x_train_norm), ' 최대값:',np.max(x_train_norm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequenential Model\n",
    "텐서플로우 케라스에서는 Sequential API라는 high level 라이브러리를 지원해준다.\n",
    "다음의 예제는 keras의 Sequential API를 이용해 최초의 CNN이라고 불리는 LeNet을 설계한 예이다. 이처럼 high level의 API를 사용하면 짧은 길이로 빠르게 작성이 가능하다.\n",
    "\n",
    "- `Conv2D(2차원 convolutional layer)` : (output_ch(or num), (kernel_h,kernel_w), activation= 'activate function', input_shape = (image_h,image_w,image_c)) # image shape에 batch size 없는 것 주의\n",
    "\n",
    "- `Maxplling2D (2차원 Maxpooling)` : (kernel_h,kernel_w)\n",
    "\n",
    "- `Flattend` : (h,w,c)를 1차원 array 변경한다(h x w x c).\n",
    "\n",
    "- `Dense (fully connectec layer)` : (output_ch, activation='상동')\n",
    "\n",
    "마지막 layer의 output 개수는 데이터셋의 분류 index 크기에 따라 다르게 설정해야한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n"
     ]
    }
   ],
   "source": [
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28,28,1)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "summary() 함수를 사용하면 설계한 모델에 대해 상세한 설명을 볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                25632     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 30,762\n",
      "Trainable params: 30,762\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터를 학습시키기전에 In [8]에서 MNIST dataset이 gray scale 이미지이기 때문에 \n",
    "input_shape=(28,28,1)으로 설정하였다.\n",
    "하지만 현재 우리가 가지고 있는 데이터는 (num,h,w)의 shape을 가지고 있기 때문에 1차원이 모자르다.\n",
    "아래와 같이 reshape 함수를 사용해 전체 shape에 변화를 주거나 np.expand_dims를 사용해 한 차원을 늘릴수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Reshape - x_train_norm shape: (60000, 28, 28)\n",
      "Before Reshape - x_test_norm shape: (10000, 28, 28)\n",
      "After Reshape - x_train_reshaped shape: (60000, 28, 28, 1)\n",
      "After Reshape - x_test_reshaped shape: (10000, 28, 28, 1)\n",
      "After Expand Dimension - np_x_train shape: (60000, 28, 28, 1)\n",
      "After Expand Dimension - np_x_test shape: (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# Reshape\n",
    "print(\"Before Reshape - x_train_norm shape: {}\".format(x_train_norm.shape))\n",
    "print(\"Before Reshape - x_test_norm shape: {}\".format(x_test_norm.shape))\n",
    "\n",
    "x_train_reshaped=x_train_norm.reshape( -1, 28, 28, 1)  # 데이터갯수에 -1을 쓰면 reshape시 자동계산됩니다.\n",
    "x_test_reshaped=x_test_norm.reshape( -1, 28, 28, 1)\n",
    "\n",
    "print(\"After Reshape - x_train_reshaped shape: {}\".format(x_train_reshaped.shape))\n",
    "print(\"After Reshape - x_test_reshaped shape: {}\".format(x_test_reshaped.shape))\n",
    "\n",
    "# Expand_dims\n",
    "\n",
    "np_x_train = np.expand_dims(x_train,axis=-1) # -1을 하면 마지막 차원에 대해 수행한다.\n",
    "np_x_test = np.expand_dims(x_test,axis=-1)\n",
    "\n",
    "print(\"After Expand Dimension - np_x_train shape: {}\".format(np_x_train.shape))\n",
    "print(\"After Expand Dimension - np_x_test shape: {}\".format(np_x_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습을 진행하기 위해서는 optimizer를 선언해야 한다.\n",
    "여기서는 adam optimizer를 사용한다.\n",
    "optimizer가 선언되었으면 fit를 사용해 훈련 이미지와 정답 label을 인자로 넘겨 학습을 진행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2132 - accuracy: 0.9363\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0673 - accuracy: 0.9797\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0495 - accuracy: 0.9846\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0389 - accuracy: 0.9875\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0333 - accuracy: 0.9894\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0279 - accuracy: 0.9910\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0237 - accuracy: 0.9923\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0211 - accuracy: 0.9932\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0165 - accuracy: 0.9947\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0146 - accuracy: 0.9951\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f87740ad110>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_reshaped, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 데이터에서 최종 accuracy를 보면 99.58%라는 높은 정확도를 기록했다.\n",
    "하지만 훈련 데이터에서 이루어진 학습은 연습문제를 잘 푸는 것과 동일하다.\n",
    "우리는 훈련한 모델을 실제 시험에 해당하는 x_test 데이터에서 높은 정확도를 기록해야 한다.\n",
    "test 데이터에서 모델의 정확도를 측정하는 방법은 다음과 같이 evaluate 함수를 사용하면 된다. evaluate에서는 2가지를 return 받을 수 있는데 첫 번째는 우리가 정의한 loss function의 값이고 accuracy 전체 데이터에 대해 맞춘 개수의 비율이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 2s - loss: 0.0364 - accuracy: 0.9893\n",
      "test_loss: 0.03640367090702057 \n",
      "test_accuracy: 0.989300012588501\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test_reshaped,y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 어떤 데이터를 잘못 추론했을까? 눈으로 확인해 보자\n",
    "model.evaluate() 대신 model.predict()를 사용하면 model 이 입력값을 보고 실제로 추론한 확률분포에 대해 출력할 수 있다.\n",
    "결과를 print해 보면 다음과 같이 array가 나오는데 이는 각각 [0에 대한 확률,1에 대한 확률,..., 9에 대한 확률]을 뜻한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.predict() 결과 :  [4.9397451e-11 7.9532339e-11 9.7254474e-07 4.5244807e-08 1.7011318e-09\n",
      " 6.4175916e-13 6.6574391e-16 9.9999881e-01 1.1608353e-08 1.3424606e-07]\n",
      "model이 추론한 가장 가능성이 높은 결과 :  7\n",
      "실제 데이터의 라벨 :  7\n"
     ]
    }
   ],
   "source": [
    "predicted_result = model.predict(x_test_reshaped)  # model이 추론한 확률값. \n",
    "predicted_labels = np.argmax(predicted_result, axis=1)\n",
    "\n",
    "idx=0  #1번째 x_test를 살펴보자. \n",
    "print('model.predict() 결과 : ', predicted_result[idx])\n",
    "print('model이 추론한 가장 가능성이 높은 결과 : ', predicted_labels[idx])\n",
    "print('실제 데이터의 라벨 : ', y_test[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실제로 7인지에 대해 확인하기 위해서는 matplotlib을 사용하면된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAM4ElEQVR4nO3db6xU9Z3H8c9nWZoY6QNQce9alC7xgc3GgCIxQTfXkDYsPsBGuikPGjZpvH2Apo0NWeM+wIeN2bZZn5DcRlO6YW1IqEqMcSHYSBq18WJQLr0BkbBwyxVsMCmYGES/++AeN1ecc2acMzNn4Pt+JZOZOd85Z74Z7odz5vyZnyNCAK5+f9N0AwAGg7ADSRB2IAnCDiRB2IEk/naQb2abXf9An0WEW02vtWa3vdb2EdvHbD9WZ1kA+svdHme3PU/SUUnfljQt6U1JGyPiTxXzsGYH+qwfa/ZVko5FxPGIuCjpt5LW11gegD6qE/abJJ2a83y6mPYFtsdsT9ieqPFeAGqqs4Ou1abClzbTI2Jc0rjEZjzQpDpr9mlJS+Y8/4ak0/XaAdAvdcL+pqRbbX/T9tckfV/S7t60BaDXut6Mj4hLth+W9D+S5kl6JiIO96wzAD3V9aG3rt6M7+xA3/XlpBoAVw7CDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBJdj88uSbZPSDov6VNJlyJiZS+aAtB7tcJeuC8i/tKD5QDoIzbjgSTqhj0k7bF9wPZYqxfYHrM9YXui5nsBqMER0f3M9t9HxGnbiyXtlfRIROyveH33bwagIxHhVtNrrdkj4nRxf1bSc5JW1VkegP7pOuy2r7X99c8fS/qOpMleNQagt+rsjb9R0nO2P1/Of0fEyz3pCkDP1frO/pXfjO/sQN/15Ts7gCsHYQeSIOxAEoQdSIKwA0n04kKYFDZs2FBae+ihhyrnPX36dGX9448/rqzv2LGjsv7++++X1o4dO1Y5L/JgzQ4kQdiBJAg7kARhB5Ig7EAShB1IgrADSXDVW4eOHz9eWlu6dOngGmnh/PnzpbXDhw8PsJPhMj09XVp78sknK+edmLhyf0WNq96A5Ag7kARhB5Ig7EAShB1IgrADSRB2IAmuZ+9Q1TXrt99+e+W8U1NTlfXbbrutsn7HHXdU1kdHR0trd999d+W8p06dqqwvWbKksl7HpUuXKusffPBBZX1kZKTr9z558mRl/Uo+zl6GNTuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJMH17FeBhQsXltaWL19eOe+BAwcq63fddVdXPXWi3e/lHz16tLLe7vyFRYsWldY2b95cOe+2bdsq68Os6+vZbT9j+6ztyTnTFtnea/vd4r78rw3AUOhkM/7XktZeNu0xSfsi4lZJ+4rnAIZY27BHxH5J5y6bvF7S9uLxdkkP9LgvAD3W7bnxN0bEjCRFxIztxWUvtD0maazL9wHQI32/ECYixiWNS+ygA5rU7aG3M7ZHJKm4P9u7lgD0Q7dh3y1pU/F4k6QXetMOgH5pe5zd9rOSRiVdL+mMpK2Snpe0U9LNkk5K+l5EXL4Tr9Wy2IxHxx588MHK+s6dOyvrk5OTpbX77ruvct5z59r+OQ+tsuPsbb+zR8TGktKaWh0BGChOlwWSIOxAEoQdSIKwA0kQdiAJLnFFYxYvLj3LWpJ06NChWvNv2LChtLZr167Kea9kDNkMJEfYgSQIO5AEYQeSIOxAEoQdSIKwA0kwZDMa0+7nnG+44YbK+ocfflhZP3LkyFfu6WrGmh1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkuB6dvTV6tWrS2uvvPJK5bzz58+vrI+OjlbW9+/fX1m/WnE9O5AcYQeSIOxAEoQdSIKwA0kQdiAJwg4kwfXs6Kt169aV1todR9+3b19l/fXXX++qp6zartltP2P7rO3JOdOesP1n2weLW/m/KICh0Mlm/K8lrW0x/ZcRsby4vdTbtgD0WtuwR8R+SecG0AuAPqqzg+5h2+8Um/kLy15ke8z2hO2JGu8FoKZuw75N0jJJyyXNSPp52QsjYjwiVkbEyi7fC0APdBX2iDgTEZ9GxGeSfiVpVW/bAtBrXYXd9sicp9+VNFn2WgDDoe1xdtvPShqVdL3taUlbJY3aXi4pJJ2Q9KM+9oghds0111TW165tdSBn1sWLFyvn3bp1a2X9k08+qazji9qGPSI2tpj8dB96AdBHnC4LJEHYgSQIO5AEYQeSIOxAElziilq2bNlSWV+xYkVp7eWXX66c97XXXuuqJ7TGmh1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkmDIZlS6//77K+vPP/98Zf2jjz4qrVVd/ipJb7zxRmUdrTFkM5AcYQeSIOxAEoQdSIKwA0kQdiAJwg4kwfXsyV133XWV9aeeeqqyPm/evMr6Sy+Vj/nJcfTBYs0OJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0lwPftVrt1x8HbHuu+8887K+nvvvVdZr7pmvd286E7X17PbXmL797anbB+2/eNi+iLbe22/W9wv7HXTAHqnk834S5J+GhG3Sbpb0mbb35L0mKR9EXGrpH3FcwBDqm3YI2ImIt4qHp+XNCXpJknrJW0vXrZd0gP9ahJAfV/p3HjbSyWtkPRHSTdGxIw0+x+C7cUl84xJGqvXJoC6Og677QWSdkn6SUT81W65D+BLImJc0nixDHbQAQ3p6NCb7fmaDfqOiPhdMfmM7ZGiPiLpbH9aBNALbdfsnl2FPy1pKiJ+Mae0W9ImST8r7l/oS4eoZdmyZZX1dofW2nn00Ucr6xxeGx6dbMavlvQDSYdsHyymPa7ZkO+0/UNJJyV9rz8tAuiFtmGPiD9IKvuCvqa37QDoF06XBZIg7EAShB1IgrADSRB2IAl+SvoqcMstt5TW9uzZU2vZW7Zsqay/+OKLtZaPwWHNDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJcJz9KjA2Vv6rXzfffHOtZb/66quV9UH+FDnqYc0OJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0lwnP0KcM8991TWH3nkkQF1gisZa3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSKKT8dmXSPqNpL+T9Jmk8Yj4T9tPSHpI0gfFSx+PiJf61Whm9957b2V9wYIFXS+73fjpFy5c6HrZGC6dnFRzSdJPI+It21+XdMD23qL2y4j4j/61B6BXOhmffUbSTPH4vO0pSTf1uzEAvfWVvrPbXipphaQ/FpMetv2O7WdsLyyZZ8z2hO2JWp0CqKXjsNteIGmXpJ9ExF8lbZO0TNJyza75f95qvogYj4iVEbGyB/0C6FJHYbc9X7NB3xERv5OkiDgTEZ9GxGeSfiVpVf/aBFBX27DbtqSnJU1FxC/mTB+Z87LvSprsfXsAeqWTvfGrJf1A0iHbB4tpj0vaaHu5pJB0QtKP+tIhann77bcr62vWrKmsnzt3rpftoEGd7I3/gyS3KHFMHbiCcAYdkARhB5Ig7EAShB1IgrADSRB2IAkPcshd24zvC/RZRLQ6VM6aHciCsANJEHYgCcIOJEHYgSQIO5AEYQeSGPSQzX+R9L9znl9fTBtGw9rbsPYl0Vu3etnbLWWFgZ5U86U3tyeG9bfphrW3Ye1LorduDao3NuOBJAg7kETTYR9v+P2rDGtvw9qXRG/dGkhvjX5nBzA4Ta/ZAQwIYQeSaCTsttfaPmL7mO3HmuihjO0Ttg/ZPtj0+HTFGHpnbU/OmbbI9l7b7xb3LcfYa6i3J2z/ufjsDtpe11BvS2z/3vaU7cO2f1xMb/Szq+hrIJ/bwL+z254n6aikb0ualvSmpI0R8aeBNlLC9glJKyOi8RMwbP+TpAuSfhMR/1hMe1LSuYj4WfEf5cKI+Lch6e0JSReaHsa7GK1oZO4w45IekPSvavCzq+jrXzSAz62JNfsqScci4nhEXJT0W0nrG+hj6EXEfkmXD8myXtL24vF2zf6xDFxJb0MhImYi4q3i8XlJnw8z3uhnV9HXQDQR9psknZrzfFrDNd57SNpj+4DtsaabaeHGiJiRZv94JC1uuJ/LtR3Ge5AuG2Z8aD67boY/r6uJsLf6faxhOv63OiLukPTPkjYXm6voTEfDeA9Ki2HGh0K3w5/X1UTYpyUtmfP8G5JON9BHSxFxurg/K+k5Dd9Q1Gc+H0G3uD/bcD//b5iG8W41zLiG4LNrcvjzJsL+pqRbbX/T9tckfV/S7gb6+BLb1xY7TmT7Wknf0fANRb1b0qbi8SZJLzTYyxcMyzDeZcOMq+HPrvHhzyNi4DdJ6zS7R/49Sf/eRA8lff2DpLeL2+Gme5P0rGY36z7R7BbRDyVdJ2mfpHeL+0VD1Nt/STok6R3NBmukod7u0exXw3ckHSxu65r+7Cr6GsjnxumyQBKcQQckQdiBJAg7kARhB5Ig7EAShB1IgrADSfwfrLwRQMBWyxMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test[idx],cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정답과 예측된 값이 다른 경우 다음과 같이 작성하면 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측확률분포: [4.1900101e-05 9.7405338e-01 2.2833545e-03 2.0673397e-08 4.9978034e-03\n",
      " 5.9448631e-08 1.8607635e-02 8.4691919e-06 7.3176575e-06 2.6883443e-08]\n",
      "라벨: 6, 예측결과: 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측확률분포: [9.1967311e-12 5.8675232e-05 6.6684616e-01 3.1938665e-02 6.8746436e-07\n",
      " 7.6033548e-13 1.2075346e-15 2.9939356e-01 2.3857057e-05 1.7383896e-03]\n",
      "라벨: 7, 예측결과: 2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAN60lEQVR4nO3df6xU9ZnH8c9HS41SUVDUq2VXaIxhY1zZoC5aNl21zZWYYE1qSsKGZpuFP2ps448sun9gsjapZutm/zBNbqMpNV0JUVux1rQEiK6aNCKhyo8tsuZuS7kBBbVAlK7w7B/30FzxzjmXOTNzBp73K7mZmfPcM+fJwOeeM/Odc76OCAE49Z3WdAMAeoOwA0kQdiAJwg4kQdiBJD7Ty43Z5qN/oMsiwuMtr7Vntz1o+7e2d9peXue5AHSX2x1nt326pB2Svixpl6TXJC2KiG0l67BnB7qsG3v2ayTtjIi3I+JPklZJWljj+QB0UZ2wXyLp92Me7yqWfYLtpbY32t5YY1sAaqrzAd14hwqfOkyPiCFJQxKH8UCT6uzZd0maMebx5yXtrtcOgG6pE/bXJF1me6btz0r6uqQ1nWkLQKe1fRgfER/bvkPSLyWdLunxiNjasc4AdFTbQ29tbYz37EDXdeVLNQBOHoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4k0faUzf1m0qRJpfXzzjuvtD579uzS+vTp01vWrr766tJ1BwcHS+uTJ08urT/11FOl9TKPPPJIaf2DDz4orX/44Ydtbxv9pVbYbQ9LOiDpiKSPI2JuJ5oC0Hmd2LP/fUS824HnAdBFvGcHkqgb9pD0K9uv21463i/YXmp7o+2NNbcFoIa6h/HXR8Ru2xdIWmv7vyPipbG/EBFDkoYkyXbU3B6ANtXas0fE7uJ2r6SfSrqmE00B6Ly2w257su2zj92X9BVJWzrVGIDOckR7R9a2Z2l0by6Nvh34z4j4bsU6tQ7jL7744pa1O++8s3Tde+65p86mS9kurbf7GndCVW+vvPJKaX3FihWl9Q0bNpxwT+iuiBj3H73t9+wR8bakv267IwA9xdAbkARhB5Ig7EAShB1IgrADSbQ99NbWxmoOvT388MMta3fddVfpuvv27Sutb9q0qa2epOrhrapTWOfNm9f2tqvUHRasel1uvPHG0vqBAwdK6+i8VkNv7NmBJAg7kARhB5Ig7EAShB1IgrADSRB2IImTapx9YGCgZa3qUtEHDx4srQ8PD7fT0oSceeaZpfWbbrqptH7vvfeW1q+77rqWtW6ffrt48eLS+qpVq2o9P04c4+xAcoQdSIKwA0kQdiAJwg4kQdiBJAg7kMRJNc6eVdU4/erVq1vWFixYULpu3X//qimdb7/99pa1F154oda2MT7G2YHkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcbZT3HPP/98aX1wcLBHnXzalClTSuuHDh3qUSenlrbH2W0/bnuv7S1jlk2zvdb2W8Xt1E42C6DzJnIY/yNJx//5Xy5pXURcJmld8RhAH6sMe0S8JGn/cYsXSlpZ3F8p6dYO9wWgwz7T5noXRsSIJEXEiO0LWv2i7aWSlra5HQAd0m7YJywihiQNSXxABzSp3aG3PbYHJKm43du5lgB0Q7thXyNpSXF/iaRnO9MOgG6pHGe3/aSkL0k6X9IeSSsk/UzSakl/Iel3kr4WEcd/iDfec3EY32MXXXRRaX3Xrl096uTTXnzxxdJ61dzvGF+rcfbK9+wRsahFiX8J4CTC12WBJAg7kARhB5Ig7EAShB1IglNcT3FnnHFGaf25554rrd9www2dbOcTqk5hnTdvXml927ZtnWznlMGlpIHkCDuQBGEHkiDsQBKEHUiCsANJEHYgia5fqQbNOnz4cGl9/fr1pfVujrMfPXq0tP7RRx91bdsZsWcHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQ4nz25SZMmldYffPDB0vrdd9/d9rbtcU+7/rNXX321tD5//vy2t30q43x2IDnCDiRB2IEkCDuQBGEHkiDsQBKEHUiC89lPcVVTNt98882l9ZkzZ5bWq8bKy5x2Wvm+5txzzy2tV10Tv+pc/mwq9+y2H7e91/aWMcsesP0H25uLnwXdbRNAXRM5jP+RpMFxlv97RFxV/Pyis20B6LTKsEfES5L296AXAF1U5wO6O2y/URzmT231S7aX2t5oe2ONbQGoqd2w/0DSFyRdJWlE0vdb/WJEDEXE3IiY2+a2AHRAW2GPiD0RcSQijkr6oaRrOtsWgE5rK+y2B8Y8/KqkLa1+F0B/qDyf3faTkr4k6XxJeyStKB5fJSkkDUtaFhEjlRvjfPZxzZo1q7R+7bXXltYHB8cbLBm1ePHi0nV7eT2D41WN0Vf1VnXN++XLl7esbdq0qXTdk1mr89krv1QTEYvGWfxY7Y4A9BRflwWSIOxAEoQdSIKwA0kQdiAJLiXdA2effXZpvWoIac6cOW1vu+7wVjd1u7eRkdajwVdeeWXpuu+9916tbTeJS0kDyRF2IAnCDiRB2IEkCDuQBGEHkiDsQBJcSroHpk5tedUuSdL+/d27xF/VqZxbt26t9fy33HJLab3qctB1lI2jS9JDDz3UsnbkyJFOt9P32LMDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKcz94HqqYePuecc9p+7kOHDtWqV1m2bFlp/dFHH21Zq3s++9q1a0vrVdNRn6o4nx1IjrADSRB2IAnCDiRB2IEkCDuQBGEHkuB89j5w+PDh0vrevXt71MmJe/nll0vrZeP4U6ZMKV336NGjpfXLL7+8tD4wMNCyVnUu/Kmocs9ue4btDba3295q+9vF8mm219p+q7gtv0IDgEZN5DD+Y0l3R8RsSX8r6Vu2/0rScknrIuIySeuKxwD6VGXYI2IkIjYV9w9I2i7pEkkLJa0sfm2lpFu71SSA+k7oPbvtSyXNkfRrSRdGxIg0+gfB9gUt1lkqaWm9NgHUNeGw2/6cpKclfSci/lh1EsMxETEkaah4Dk6EARoyoaE325M0GvSfRMQzxeI9tgeK+oCk/v3IGED1nt2ju/DHJG2PiEfGlNZIWiLpe8Xts13pEH2t6lLUw8PDLWtXXHFF6bpVp7hOmzattD558uTSejYTOYy/XtI/SHrT9uZi2f0aDflq29+U9DtJX+tOiwA6oTLsEfGypFZv0G/sbDsAuoWvywJJEHYgCcIOJEHYgSQIO5AEp7iiq5544omWtbIplSdix44dpfX58+e3rO3cubPWtk9G7NmBJAg7kARhB5Ig7EAShB1IgrADSRB2IAmmbEZXTZ8+vWVt/fr1pevOnj271rbff//9lrWqy1Dv27ev1rabxJTNQHKEHUiCsANJEHYgCcIOJEHYgSQIO5AE57Ojq955552Wtfvuu6903dtuu620ftZZZ5XWy8b4q6bJPhWxZweSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJCrPZ7c9Q9KPJV0k6aikoYj4D9sPSPonSccGUu+PiF9UPBfnswNd1up89omEfUDSQERssn22pNcl3SrpdkkHI+LfJtoEYQe6r1XYJzI/+4ikkeL+AdvbJV3S2fYAdNsJvWe3famkOZJ+XSy6w/Ybth+3PbXFOkttb7S9sVanAGqZ8DXobH9O0ouSvhsRz9i+UNK7kkLSv2r0UP8fK56Dw3igy9p+zy5JtidJ+rmkX0bEI+PUL5X084i4ouJ5CDvQZW1fcNK2JT0mafvYoBcf3B3zVUlb6jYJoHsm8mn8FyX9l6Q3NTr0Jkn3S1ok6SqNHsYPS1pWfJhX9lzs2YEuq3UY3ymEHeg+rhsPJEfYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IotdTNr8r6X/HPD6/WNaP+rW3fu1Lord2dbK3v2xV6On57J/auL0xIuY21kCJfu2tX/uS6K1dveqNw3ggCcIOJNF02Ica3n6Zfu2tX/uS6K1dPemt0ffsAHqn6T07gB4h7EASjYTd9qDt39reaXt5Ez20YnvY9pu2Nzc9P10xh95e21vGLJtme63tt4rbcefYa6i3B2z/oXjtNtte0FBvM2xvsL3d9lbb3y6WN/ralfTVk9et5+/ZbZ8uaYekL0vaJek1SYsiYltPG2nB9rCkuRHR+BcwbP+dpIOSfnxsai3bD0vaHxHfK/5QTo2If+6T3h7QCU7j3aXeWk0z/g01+Np1cvrzdjSxZ79G0s6IeDsi/iRplaSFDfTR9yLiJUn7j1u8UNLK4v5Kjf5n6bkWvfWFiBiJiE3F/QOSjk0z3uhrV9JXTzQR9ksk/X7M413qr/neQ9KvbL9ue2nTzYzjwmPTbBW3FzTcz/Eqp/HupeOmGe+b166d6c/raiLs401N00/jf9dHxN9IulnSt4rDVUzMDyR9QaNzAI5I+n6TzRTTjD8t6TsR8ccmexlrnL568ro1EfZdkmaMefx5Sbsb6GNcEbG7uN0r6acafdvRT/Ycm0G3uN3bcD9/FhF7IuJIRByV9EM1+NoV04w/LeknEfFMsbjx1268vnr1ujUR9tckXWZ7pu3PSvq6pDUN9PEpticXH5zI9mRJX1H/TUW9RtKS4v4SSc822Msn9Ms03q2mGVfDr13j059HRM9/JC3Q6Cfy/yPpX5rooUVfsyT9pvjZ2nRvkp7U6GHd/2n0iOibks6TtE7SW8XttD7q7QmNTu39hkaDNdBQb1/U6FvDNyRtLn4WNP3alfTVk9eNr8sCSfANOiAJwg4kQdiBJAg7kARhB5Ig7EAShB1I4v8BQLB/L9gxGScAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측확률분포: [2.7486814e-07 9.6847779e-01 8.7136775e-03 1.5045678e-04 9.8921556e-04\n",
      " 1.3519572e-07 2.8031352e-05 2.1619080e-02 1.6811973e-05 4.5770403e-06]\n",
      "라벨: 7, 예측결과: 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측확률분포: [4.89199685e-08 9.65211630e-01 1.23075615e-05 1.07160713e-06\n",
      " 1.26358937e-04 8.19254442e-10 2.48715319e-11 3.42420526e-02\n",
      " 1.63730947e-04 2.42947979e-04]\n",
      "라벨: 7, 예측결과: 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측확률분포: [5.8001245e-08 3.6234787e-01 2.6509467e-01 1.2264707e-01 1.7990474e-02\n",
      " 3.1744319e-04 9.2693690e-06 2.0293407e-01 7.2774194e-05 2.8586308e-02]\n",
      "라벨: 7, 예측결과: 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "wrong_predict_list=[]\n",
    "for i, _ in enumerate(predicted_labels):\n",
    "    # i번째 test_labels과 y_test이 다른 경우만 모아 봅시다. \n",
    "    if predicted_labels[i] != y_test[i]:\n",
    "        wrong_predict_list.append(i)\n",
    "\n",
    "# wrong_predict_list 에서 랜덤하게 5개만 뽑아봅시다.\n",
    "samples = random.choices(population=wrong_predict_list, k=5)\n",
    "\n",
    "for n in samples:\n",
    "    print(\"예측확률분포: \" + str(predicted_result[n]))\n",
    "    print(\"라벨: \" + str(y_test[n]) + \", 예측결과: \" + str(predicted_labels[n]))\n",
    "    plt.imshow(x_test[n], cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 더 좋은 네트워크 만들어보기\n",
    "현재 설계된 모델에서 가능한 하이퍼 파라미터는 각 layer의 output 크기, epoch, kernel의 크기 등등이 있다. 이를 조절해서 더 높은 값을 만들어보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                102464    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 121,930\n",
      "Trainable params: 121,930\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1428 - accuracy: 0.9564\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0458 - accuracy: 0.9857\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0317 - accuracy: 0.9899\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0244 - accuracy: 0.9922\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0190 - accuracy: 0.9939\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0140 - accuracy: 0.9955\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0129 - accuracy: 0.9957\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0098 - accuracy: 0.9967\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0088 - accuracy: 0.9971\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0077 - accuracy: 0.9973\n",
      "313/313 - 3s - loss: 0.0338 - accuracy: 0.9913\n",
      "test_loss: 0.033801209181547165 \n",
      "test_accuracy: 0.9912999868392944\n"
     ]
    }
   ],
   "source": [
    "#바꿔 볼 수 있는 하이퍼파라미터들\n",
    "n_channel_1=32\n",
    "n_channel_2=64\n",
    "n_dense=64\n",
    "n_train_epoch=10\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,1)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_train_reshaped, y_train, epochs=n_train_epoch)\n",
    "\n",
    "# 모델 시험\n",
    "test_loss, test_accuracy = model.evaluate(x_test_reshaped, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 가위,바위,보 분류기 만들기\n",
    "\n",
    "## 데이터 준비\n",
    "\n",
    "구글의 teachable machine 사이트에서 쉽게 만들 수 있다.\n",
    "https://teachablemachine.withgoogle.com/\n",
    "webcam으로 찍어서 우측 상단의 ...을 누르면 샘플들을 다운 받을 수 있다.\n",
    "\n",
    "rock_scissor_paper 폴더를 만들고 각각의 class에 대해 경로를 지정해 주었다.\n",
    "```\n",
    "$ mkdir -p ~/aiffel/rock_scissor_paper/scissor\n",
    "$ mkdir -p ~/aiffel/rock_scissor_paper/rock\n",
    "$ mkdir -p ~/aiffel/rock_scissor_paper/paper\n",
    "```\n",
    "\n",
    "구글에서 다운로드 받은 데이터의 size는 224x224인데 현재 설계된 모델에 맞게 이미지를 resize해야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in /home/aiffel0042/anaconda3/lib/python3.7/site-packages (7.2.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pillow   \n",
    "from PIL import Image\n",
    "import os, glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/aiffel0042/Downloads/train/paper', '/home/aiffel0042/Downloads/train/scissor', '/home/aiffel0042/Downloads/train/rock']\n"
     ]
    }
   ],
   "source": [
    "# image_dir_path = os.getenv(\"HOME\")+\"/Downloads/train/\"\n",
    "# image_dir_path=glob.glob(image_dir_path+'*')\n",
    "# print(image_dir_path)\n",
    "# images = [glob.glob(image_dir_path[i]+\"/*.jpg\") for i in range(len(image_dir_path))]\n",
    "\n",
    "# target_size=(28,28)\n",
    "\n",
    "# for i in range(len(image_dir_path)):\n",
    "#     for img in images[i]:\n",
    "#         old_img=Image.open(img)\n",
    "#         new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "#         new_img.save(img,\"JPEG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jisu_dir_path = os.getenv(\"HOME\")+\"/Downloads/rock_scissor_paper/\"\n",
    "# my_dir_path = os.getenv(\"HOME\")+\"/Downloads/train/\"\n",
    "# class_folder = [\"rock/\",\"scissor/\",\"paper/\"]\n",
    "\n",
    "# images = [glob.glob(jisu_dir_path + class_folder[i]+\"*.jpg\") for i in range(3)]\n",
    "# print(images)\n",
    "# offset = 100\n",
    "# target_size=(28,28)\n",
    "\n",
    "# for i in range(3):\n",
    "#     for image in images[i]:\n",
    "#         print(image)\n",
    "#         out_num = str(offset+int(image.split('/')[-1].split('.')[0]))\n",
    "#         if not os.path.exists(my_dir_path+class_folder[i]):\n",
    "#             os.makedirs(my_dir_path+class_folder[i])\n",
    "#         out_path = my_dir_path+class_folder[i]+out_num+'.jpg'\n",
    "#         old_img=Image.open(image)\n",
    "#         new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "#         new_img.save(out_path,\"JPEG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래의 input_data() 함수는 입력으로 이미지가 있는 폴더 위치를 받고 클래스 별로 label을 부여한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 1200 입니다.\n",
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n",
      "x_train shape: (1200, 28, 28, 3)\n",
      "y_train shape: (1200,)\n",
      "x_test shape: (300, 28, 28, 3)\n",
      "y_test shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1337)\n",
    "from PIL import Image\n",
    "import os, glob\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "def load_data(img_path,number_of_data):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2   # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs/255.0, labels\n",
    "\n",
    "train_dir_path = os.getenv(\"HOME\") + \"/Downloads/train\"\n",
    "(x_train, y_train)=load_data(train_dir_path,1200)\n",
    "test_dir_path = os.getenv(\"HOME\") + \"/Downloads/test\"\n",
    "(x_test, y_test)=load_data(test_dir_path,300)\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저 이전과 동일하게 모델을 설계하고 결과를 확인해본다.\n",
    "현재 데이터는 데이터당 3차원의 정보를 가지고 있으므로 reshape을 하지 않아도 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 11, 11, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                25632     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 30,819\n",
      "Trainable params: 30,819\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "38/38 [==============================] - 4s 96ms/step - loss: 1.0978 - accuracy: 0.3867\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 1.0589 - accuracy: 0.5067\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.9715 - accuracy: 0.5575\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.9081 - accuracy: 0.5608\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.8558 - accuracy: 0.5975\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.7968 - accuracy: 0.6350\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.7296 - accuracy: 0.6983\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.6835 - accuracy: 0.7367\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6290 - accuracy: 0.7492\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5812 - accuracy: 0.7783\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f86fc0a6510>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 2s - loss: 1.5498 - accuracy: 0.4067\n",
      "test_loss: 1.5498270988464355 \n",
      "test_accuracy: 0.40666666626930237\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "약 40 정도의 정확도가 나오는데 데이터 augmentation과 model의 변경을 통해 정확도를 올릴 것이다.\n",
    "\n",
    "아래와 같이 keras의 DataGenerator를 사용하면 이미지를 augmentation할 수 있다.\n",
    "\n",
    "- `width_shift_range` : 좌우로 이동\n",
    "- `height_shift_range` : 상하로 이동\n",
    "- `zoom_range` : 줌 인/아웃\n",
    "- `ratation_range` : 회전\n",
    "- `horizontal_flip` : 좌우 반전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "width_shift_range = 0.1,\n",
    "height_shift_range = 0.1,\n",
    "    zoom_range = [0.8, 1.2],\n",
    "    rotation_range = 10,\n",
    "horizontal_flip=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "augmentation을 했음에도 train data가 너무 작아 한 층 씩만 추가했다.\n",
    "n_channel의 경우에도 학습데이터 대비 파라미터의 양이 너무 많아져 overffiting이 발생한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 26, 26, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 13, 13, 32)        4640      \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 13, 13, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                36896     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 53,651\n",
      "Trainable params: 53,651\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_channel_1=16\n",
    "n_channel_2=32\n",
    "n_dense=32\n",
    "n_train_epoch=20\n",
    "n_model=keras.models.Sequential()\n",
    "n_model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "n_model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', padding='same'))\n",
    "\n",
    "n_model.add(keras.layers.MaxPool2D(2,2))\n",
    "n_model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu',padding='same'))\n",
    "n_model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu', padding='same'))\n",
    "n_model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "\n",
    "n_model.add(keras.layers.Flatten())\n",
    "n_model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "n_model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "n_model.summary()\n",
    "n_model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data generator를 사용할때는 아래와 같이 fit이 아닌 fit_generator 함수를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-26-ff1126a36eb6>:2: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/20\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 1.1019 - accuracy: 0.3283\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 1.0996 - accuracy: 0.3583\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 1.0950 - accuracy: 0.3967\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 1.0844 - accuracy: 0.4142\n",
      "Epoch 5/20\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 1.0639 - accuracy: 0.4542\n",
      "Epoch 6/20\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 1.0515 - accuracy: 0.4467\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 1.0193 - accuracy: 0.4900\n",
      "Epoch 8/20\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.9858 - accuracy: 0.5350\n",
      "Epoch 9/20\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.9625 - accuracy: 0.5358\n",
      "Epoch 10/20\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.9055 - accuracy: 0.5942\n",
      "Epoch 11/20\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.8838 - accuracy: 0.5942\n",
      "Epoch 12/20\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 0.8560 - accuracy: 0.6217\n",
      "Epoch 13/20\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 0.8090 - accuracy: 0.6683\n",
      "Epoch 14/20\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.7937 - accuracy: 0.6592\n",
      "Epoch 15/20\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.7337 - accuracy: 0.7142\n",
      "Epoch 16/20\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 0.7020 - accuracy: 0.7158\n",
      "Epoch 17/20\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.6475 - accuracy: 0.7333\n",
      "Epoch 18/20\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.6356 - accuracy: 0.7175\n",
      "Epoch 19/20\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 0.6026 - accuracy: 0.7467\n",
      "Epoch 20/20\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.5418 - accuracy: 0.7850\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f86fc799510>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 훈련\n",
    "n_model.fit_generator(datagen.flow(x_train, y_train,batch_size= 100),steps_per_epoch = x_train.shape[0]//100,epochs=n_train_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결과는 아래와 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 3s - loss: 0.8786 - accuracy: 0.6167\n",
      "test_loss: 0.878575325012207 \n",
      "test_accuracy: 0.6166666746139526\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = n_model.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 개선사항\n",
    "- #### data augment \n",
    "- #### conv layer 2개 추가 (더 깊은 네트워크, augmentation을 해서 어느정도 추가 가능할것이라고 판단함)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
